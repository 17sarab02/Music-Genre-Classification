{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **IMPORTING LIBRARIES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***MACHINE LEARNING LIBRARIES***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.math import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **IMPORTING DATA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***READING CSV's***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READING FILES\n",
    "data30 = pd.read_csv('Data/features_30_sec.csv')\n",
    "data3 = pd.read_csv('Data/features_3_sec.csv')\n",
    "\n",
    "# REMOVING CORRUPT FILE (FOUND WHILE TESTING)\n",
    "data30 = data30[data30['filename'] != 'jazz.00054.wav']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***PRINTING THE DATA***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>length</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_var</th>\n",
       "      <th>spectral_bandwidth_mean</th>\n",
       "      <th>spectral_bandwidth_var</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "      <th>mfcc20_mean</th>\n",
       "      <th>mfcc20_var</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blues.00000.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.350088</td>\n",
       "      <td>0.088757</td>\n",
       "      <td>0.130228</td>\n",
       "      <td>0.002827</td>\n",
       "      <td>1784.165850</td>\n",
       "      <td>129774.064525</td>\n",
       "      <td>2002.449060</td>\n",
       "      <td>85882.761315</td>\n",
       "      <td>...</td>\n",
       "      <td>52.420910</td>\n",
       "      <td>-1.690215</td>\n",
       "      <td>36.524071</td>\n",
       "      <td>-0.408979</td>\n",
       "      <td>41.597103</td>\n",
       "      <td>-2.303523</td>\n",
       "      <td>55.062923</td>\n",
       "      <td>1.221291</td>\n",
       "      <td>46.936035</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blues.00001.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.340914</td>\n",
       "      <td>0.094980</td>\n",
       "      <td>0.095948</td>\n",
       "      <td>0.002373</td>\n",
       "      <td>1530.176679</td>\n",
       "      <td>375850.073649</td>\n",
       "      <td>2039.036516</td>\n",
       "      <td>213843.755497</td>\n",
       "      <td>...</td>\n",
       "      <td>55.356403</td>\n",
       "      <td>-0.731125</td>\n",
       "      <td>60.314529</td>\n",
       "      <td>0.295073</td>\n",
       "      <td>48.120598</td>\n",
       "      <td>-0.283518</td>\n",
       "      <td>51.106190</td>\n",
       "      <td>0.531217</td>\n",
       "      <td>45.786282</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blues.00002.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.363637</td>\n",
       "      <td>0.085275</td>\n",
       "      <td>0.175570</td>\n",
       "      <td>0.002746</td>\n",
       "      <td>1552.811865</td>\n",
       "      <td>156467.643368</td>\n",
       "      <td>1747.702312</td>\n",
       "      <td>76254.192257</td>\n",
       "      <td>...</td>\n",
       "      <td>40.598766</td>\n",
       "      <td>-7.729093</td>\n",
       "      <td>47.639427</td>\n",
       "      <td>-1.816407</td>\n",
       "      <td>52.382141</td>\n",
       "      <td>-3.439720</td>\n",
       "      <td>46.639660</td>\n",
       "      <td>-2.231258</td>\n",
       "      <td>30.573025</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blues.00003.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.404785</td>\n",
       "      <td>0.093999</td>\n",
       "      <td>0.141093</td>\n",
       "      <td>0.006346</td>\n",
       "      <td>1070.106615</td>\n",
       "      <td>184355.942417</td>\n",
       "      <td>1596.412872</td>\n",
       "      <td>166441.494769</td>\n",
       "      <td>...</td>\n",
       "      <td>44.427753</td>\n",
       "      <td>-3.319597</td>\n",
       "      <td>50.206673</td>\n",
       "      <td>0.636965</td>\n",
       "      <td>37.319130</td>\n",
       "      <td>-0.619121</td>\n",
       "      <td>37.259739</td>\n",
       "      <td>-3.407448</td>\n",
       "      <td>31.949339</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blues.00004.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.308526</td>\n",
       "      <td>0.087841</td>\n",
       "      <td>0.091529</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>1835.004266</td>\n",
       "      <td>343399.939274</td>\n",
       "      <td>1748.172116</td>\n",
       "      <td>88445.209036</td>\n",
       "      <td>...</td>\n",
       "      <td>86.099236</td>\n",
       "      <td>-5.454034</td>\n",
       "      <td>75.269707</td>\n",
       "      <td>-0.916874</td>\n",
       "      <td>53.613918</td>\n",
       "      <td>-4.404827</td>\n",
       "      <td>62.910812</td>\n",
       "      <td>-11.703234</td>\n",
       "      <td>55.195160</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>rock.00095.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.352063</td>\n",
       "      <td>0.080487</td>\n",
       "      <td>0.079486</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>2008.149458</td>\n",
       "      <td>282174.689224</td>\n",
       "      <td>2106.541053</td>\n",
       "      <td>88609.749506</td>\n",
       "      <td>...</td>\n",
       "      <td>45.050526</td>\n",
       "      <td>-13.289984</td>\n",
       "      <td>41.754955</td>\n",
       "      <td>2.484145</td>\n",
       "      <td>36.778877</td>\n",
       "      <td>-6.713265</td>\n",
       "      <td>54.866825</td>\n",
       "      <td>-1.193787</td>\n",
       "      <td>49.950665</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>rock.00096.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.398687</td>\n",
       "      <td>0.075086</td>\n",
       "      <td>0.076458</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>2006.843354</td>\n",
       "      <td>182114.709510</td>\n",
       "      <td>2068.942009</td>\n",
       "      <td>82426.016726</td>\n",
       "      <td>...</td>\n",
       "      <td>33.851742</td>\n",
       "      <td>-10.848309</td>\n",
       "      <td>39.395096</td>\n",
       "      <td>1.881229</td>\n",
       "      <td>32.010040</td>\n",
       "      <td>-7.461491</td>\n",
       "      <td>39.196327</td>\n",
       "      <td>-2.795338</td>\n",
       "      <td>31.773624</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>rock.00097.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.432142</td>\n",
       "      <td>0.075268</td>\n",
       "      <td>0.081651</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>2077.526598</td>\n",
       "      <td>231657.968040</td>\n",
       "      <td>1927.293153</td>\n",
       "      <td>74717.124394</td>\n",
       "      <td>...</td>\n",
       "      <td>33.597008</td>\n",
       "      <td>-12.845291</td>\n",
       "      <td>36.367264</td>\n",
       "      <td>3.440978</td>\n",
       "      <td>36.001110</td>\n",
       "      <td>-12.588070</td>\n",
       "      <td>42.502201</td>\n",
       "      <td>-2.106337</td>\n",
       "      <td>29.865515</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>rock.00098.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.362485</td>\n",
       "      <td>0.091506</td>\n",
       "      <td>0.083860</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>1398.699344</td>\n",
       "      <td>240318.731073</td>\n",
       "      <td>1818.450280</td>\n",
       "      <td>109090.207161</td>\n",
       "      <td>...</td>\n",
       "      <td>46.324894</td>\n",
       "      <td>-4.416050</td>\n",
       "      <td>43.583942</td>\n",
       "      <td>1.556207</td>\n",
       "      <td>34.331261</td>\n",
       "      <td>-5.041897</td>\n",
       "      <td>47.227180</td>\n",
       "      <td>-3.590644</td>\n",
       "      <td>41.299088</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>rock.00099.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.358401</td>\n",
       "      <td>0.085884</td>\n",
       "      <td>0.054454</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>1609.795082</td>\n",
       "      <td>422203.216152</td>\n",
       "      <td>1797.213044</td>\n",
       "      <td>120115.632927</td>\n",
       "      <td>...</td>\n",
       "      <td>59.167755</td>\n",
       "      <td>-7.069775</td>\n",
       "      <td>73.760391</td>\n",
       "      <td>0.028346</td>\n",
       "      <td>76.504326</td>\n",
       "      <td>-2.025783</td>\n",
       "      <td>72.189316</td>\n",
       "      <td>1.155239</td>\n",
       "      <td>49.662510</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  length  chroma_stft_mean  chroma_stft_var  rms_mean  \\\n",
       "0    blues.00000.wav  661794          0.350088         0.088757  0.130228   \n",
       "1    blues.00001.wav  661794          0.340914         0.094980  0.095948   \n",
       "2    blues.00002.wav  661794          0.363637         0.085275  0.175570   \n",
       "3    blues.00003.wav  661794          0.404785         0.093999  0.141093   \n",
       "4    blues.00004.wav  661794          0.308526         0.087841  0.091529   \n",
       "..               ...     ...               ...              ...       ...   \n",
       "995   rock.00095.wav  661794          0.352063         0.080487  0.079486   \n",
       "996   rock.00096.wav  661794          0.398687         0.075086  0.076458   \n",
       "997   rock.00097.wav  661794          0.432142         0.075268  0.081651   \n",
       "998   rock.00098.wav  661794          0.362485         0.091506  0.083860   \n",
       "999   rock.00099.wav  661794          0.358401         0.085884  0.054454   \n",
       "\n",
       "      rms_var  spectral_centroid_mean  spectral_centroid_var  \\\n",
       "0    0.002827             1784.165850          129774.064525   \n",
       "1    0.002373             1530.176679          375850.073649   \n",
       "2    0.002746             1552.811865          156467.643368   \n",
       "3    0.006346             1070.106615          184355.942417   \n",
       "4    0.002303             1835.004266          343399.939274   \n",
       "..        ...                     ...                    ...   \n",
       "995  0.000345             2008.149458          282174.689224   \n",
       "996  0.000588             2006.843354          182114.709510   \n",
       "997  0.000322             2077.526598          231657.968040   \n",
       "998  0.001211             1398.699344          240318.731073   \n",
       "999  0.000336             1609.795082          422203.216152   \n",
       "\n",
       "     spectral_bandwidth_mean  spectral_bandwidth_var  ...  mfcc16_var  \\\n",
       "0                2002.449060            85882.761315  ...   52.420910   \n",
       "1                2039.036516           213843.755497  ...   55.356403   \n",
       "2                1747.702312            76254.192257  ...   40.598766   \n",
       "3                1596.412872           166441.494769  ...   44.427753   \n",
       "4                1748.172116            88445.209036  ...   86.099236   \n",
       "..                       ...                     ...  ...         ...   \n",
       "995              2106.541053            88609.749506  ...   45.050526   \n",
       "996              2068.942009            82426.016726  ...   33.851742   \n",
       "997              1927.293153            74717.124394  ...   33.597008   \n",
       "998              1818.450280           109090.207161  ...   46.324894   \n",
       "999              1797.213044           120115.632927  ...   59.167755   \n",
       "\n",
       "     mfcc17_mean  mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  \\\n",
       "0      -1.690215   36.524071    -0.408979   41.597103    -2.303523   \n",
       "1      -0.731125   60.314529     0.295073   48.120598    -0.283518   \n",
       "2      -7.729093   47.639427    -1.816407   52.382141    -3.439720   \n",
       "3      -3.319597   50.206673     0.636965   37.319130    -0.619121   \n",
       "4      -5.454034   75.269707    -0.916874   53.613918    -4.404827   \n",
       "..           ...         ...          ...         ...          ...   \n",
       "995   -13.289984   41.754955     2.484145   36.778877    -6.713265   \n",
       "996   -10.848309   39.395096     1.881229   32.010040    -7.461491   \n",
       "997   -12.845291   36.367264     3.440978   36.001110   -12.588070   \n",
       "998    -4.416050   43.583942     1.556207   34.331261    -5.041897   \n",
       "999    -7.069775   73.760391     0.028346   76.504326    -2.025783   \n",
       "\n",
       "     mfcc19_var  mfcc20_mean  mfcc20_var  label  \n",
       "0     55.062923     1.221291   46.936035  blues  \n",
       "1     51.106190     0.531217   45.786282  blues  \n",
       "2     46.639660    -2.231258   30.573025  blues  \n",
       "3     37.259739    -3.407448   31.949339  blues  \n",
       "4     62.910812   -11.703234   55.195160  blues  \n",
       "..          ...          ...         ...    ...  \n",
       "995   54.866825    -1.193787   49.950665   rock  \n",
       "996   39.196327    -2.795338   31.773624   rock  \n",
       "997   42.502201    -2.106337   29.865515   rock  \n",
       "998   47.227180    -3.590644   41.299088   rock  \n",
       "999   72.189316     1.155239   49.662510   rock  \n",
       "\n",
       "[999 rows x 60 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PROCESSING DATA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***PROCESSING AND STORING WAVEFORMS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveforms = []\n",
    "\n",
    "for i, j in data30.iterrows():\n",
    "    path = (os.path.join('Data', 'genres_original', j.label, j.filename))\n",
    "    waveform = librosa.load(path, res_type = 'kaiser_fast')\n",
    "    waveforms.append(waveform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***FEATURE EXTRACTION***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalised_data = []\n",
    "\n",
    "for audio, sample_rate in waveforms:\n",
    "    features_list = []\n",
    "\n",
    "    features = librosa.feature.mfcc(y=audio, sr = sample_rate, n_mfcc= 30)\n",
    "    averaged_features = np.mean(features, axis=1)\n",
    "    variance_features = np.var(features, axis=1)\n",
    "    features_list.extend(averaged_features)\n",
    "    features_list.extend(variance_features)\n",
    "\n",
    "    tempo_beat = librosa.beat.beat_track(y=audio, sr = sample_rate)\n",
    "    tempo = tempo_beat[0]\n",
    "    beat_mean = np.mean(tempo_beat[1])\n",
    "    beat_var = np.var(tempo_beat[1])\n",
    "    features_list.append(tempo)\n",
    "    features_list.append(beat_mean)\n",
    "    features_list.append(beat_var)\n",
    "\n",
    "    onset = librosa.onset.onset_strength(y=audio, sr = sample_rate)\n",
    "    averaged_onset = np.mean(onset)\n",
    "    variance_onset = np.var(onset)\n",
    "    features_list.append(averaged_onset)\n",
    "    features_list.append(variance_onset)\n",
    "\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr = sample_rate)\n",
    "    averaged_mel = np.mean(mel_spectrogram, axis = 1)\n",
    "    variance_mel = np.var(mel_spectrogram, axis = 1)\n",
    "    features_list.extend(averaged_mel)\n",
    "    features_list.extend(variance_mel)\n",
    "\n",
    "    chroma_cens = librosa.feature.chroma_cens(y=audio, sr = sample_rate)\n",
    "    averaged_cens = np.mean(chroma_cens, axis = 1)\n",
    "    variance_cens = np.var(chroma_cens, axis = 1)\n",
    "    features_list.extend(averaged_cens)\n",
    "    features_list.extend(variance_cens)\n",
    "\n",
    "    chroma_cqt = librosa.feature.chroma_cqt(y=audio, sr = sample_rate)\n",
    "    averaged_cqt = np.mean(chroma_cqt, axis = 1)\n",
    "    variance_cqt = np.var(chroma_cqt, axis = 1)\n",
    "    features_list.extend(averaged_cqt)\n",
    "    features_list.extend(variance_cqt)\n",
    "\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=audio, sr = sample_rate)\n",
    "    averaged_stft = np.mean(chroma_stft, axis = 1)\n",
    "    variance_stft = np.var(chroma_stft, axis = 1)\n",
    "    features_list.extend(averaged_stft)\n",
    "    features_list.extend(variance_stft)\n",
    "\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr = sample_rate)\n",
    "    averaged_rolloff = np.mean(spectral_rolloff, axis = 1)\n",
    "    variance_rolloff = np.var(spectral_rolloff, axis = 1)\n",
    "    features_list.extend(averaged_rolloff)\n",
    "    features_list.extend(variance_rolloff)\n",
    "\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr = sample_rate)\n",
    "    averaged_bandwidth = np.mean(spectral_bandwidth, axis = 1)\n",
    "    variance_bandwidth = np.var(spectral_bandwidth, axis = 1)\n",
    "    features_list.extend(averaged_bandwidth)\n",
    "    features_list.extend(variance_bandwidth)\n",
    "\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=audio, sr = sample_rate)\n",
    "    averaged_contrast = np.mean(spectral_contrast, axis = 1)\n",
    "    variance_contrast = np.var(spectral_contrast, axis = 1)\n",
    "    features_list.extend(averaged_contrast)\n",
    "    features_list.extend(variance_contrast)\n",
    "\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=audio, sr = sample_rate)\n",
    "    averaged_centroid = np.mean(spectral_centroid, axis = 1)\n",
    "    variance_centroid = np.var(spectral_centroid, axis = 1)\n",
    "    features_list.extend(averaged_centroid)\n",
    "    features_list.extend(variance_centroid)\n",
    "\n",
    "    spectral_flatness = librosa.feature.spectral_flatness(y=audio)\n",
    "    averaged_flatness = np.mean(spectral_flatness, axis = 1)\n",
    "    variance_flatness = np.var(spectral_flatness, axis = 1)\n",
    "    features_list.extend(averaged_flatness)\n",
    "    features_list.extend(variance_flatness)\n",
    "\n",
    "    finalised_data.append(np.array(features_list))\n",
    "    \n",
    "\n",
    "finalised_data = np.array(finalised_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORTING PARAMETERS TO CSV (TO AVOID HAVING TO RUN PREVIOUS CELLS IN CASE OF A CRASH)\n",
    "pd.DataFrame(finalised_data).to_csv('Parameters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 415)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Parameters.csv')\n",
    "data.drop(columns = ['Unnamed: 0'], inplace = True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TRAINING MODEL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***SPLITTING DATA (INTO TRAINING AND TESTING DATA)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = data\n",
    "Y = np.array(data30['label'])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.35, random_state=90, stratify=Y)\n",
    "\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "labels = data30['label'].unique()\n",
    "Y_train_hotencoded = to_categorical(labelencoder.fit_transform(Y_train))\n",
    "Y_test_hotencoded = to_categorical(labelencoder.fit_transform(Y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***MAKING LIST OF MODELS AND HYPER-PARAMETERS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter = 1000),\n",
    "    'DecisionTree': DecisionTreeClassifier(),\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'KNN_Classifier': KNeighborsClassifier(),\n",
    "    'SVM_Classifier': SVC()\n",
    "}\n",
    "\n",
    "hyper_params = {\n",
    "    'LogisticRegression': {\n",
    "        'C': [1, 10, 100, 100000],\n",
    "        'penalty': ['l2', 'none'],\n",
    "        'solver': ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "    },\n",
    "    'DecisionTree': {\n",
    "        'max_depth': [None, 5, 10, 20, 40],\n",
    "        'max_features': [None, 'sqrt', 'log2'],\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'n_estimators': [25, 50, 75, 100],\n",
    "        'max_depth': [None, 5, 10, 20, 40],\n",
    "        'max_features': [None, 'sqrt', 'log2'],\n",
    "    },\n",
    "    'KNN_Classifier': {\n",
    "        'n_neighbors': [5, 10, 15],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'algorithm': ['ball_tree', 'kd_tree', 'brute'],\n",
    "        'metric': ['minkowski', 'manhattan', 'euclidean']\n",
    "    },\n",
    "    'SVM_Classifier': {\n",
    "        'degree': [2, 3, 4],\n",
    "        'C': [1, 10, 100, 100000],\n",
    "        'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***CHECKING WHICH KIND OF SCALING WORKS BETTER***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LogisticRegression with MinMax Scaling: 72.57%\n",
      "Accuracy of LogisticRegression with Standard Scaling: 71.43%\n",
      "Min-max scaling works better by 1.14%\n",
      "\n",
      "Accuracy of DecisionTree with MinMax Scaling: 49.43%\n",
      "Accuracy of DecisionTree with Standard Scaling: 50.86%\n",
      "Standard scaling works better by 1.43%\n",
      "\n",
      "Accuracy of RandomForest with MinMax Scaling: 70.29%\n",
      "Accuracy of RandomForest with Standard Scaling: 71.71%\n",
      "Standard scaling works better by 1.42%\n",
      "\n",
      "Accuracy of KNN_Classifier with MinMax Scaling: 65.71%\n",
      "Accuracy of KNN_Classifier with Standard Scaling: 63.71%\n",
      "Min-max scaling works better by 2.0%\n",
      "\n",
      "Accuracy of SVM_Classifier with MinMax Scaling: 70.57%\n",
      "Accuracy of SVM_Classifier with Standard Scaling: 69.71%\n",
      "Min-max scaling works better by 0.86%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "scaler1 = MinMaxScaler()\n",
    "scaler2 = StandardScaler()\n",
    "scaler1.fit(X_train)\n",
    "scaler2.fit(X_train)\n",
    "\n",
    "mm_X_train = scaler1.transform(X_train)\n",
    "mm_X_test = scaler1.transform(X_test)\n",
    "\n",
    "ss_X_train = scaler2.transform(X_train)\n",
    "ss_X_test = scaler2.transform(X_test)\n",
    "\n",
    "for i in models:\n",
    "    current_model = models[i]\n",
    "    current_model.fit(mm_X_train, Y_train)\n",
    "    minmax_accuracy = round(accuracy_score(current_model.predict(mm_X_test), Y_test)*100, 2)\n",
    "    print('Accuracy of {} with MinMax Scaling: {}%'.format(i, minmax_accuracy))\n",
    "    current_model = models[i]\n",
    "    current_model.fit(ss_X_train, Y_train)\n",
    "    standard_accuracy = round(accuracy_score(current_model.predict(ss_X_test), Y_test)*100, 2)\n",
    "    print('Accuracy of {} with Standard Scaling: {}%'.format(i, standard_accuracy))\n",
    "    if(standard_accuracy > minmax_accuracy):\n",
    "        print('Standard scaling works better by {}%'.format(round(standard_accuracy - minmax_accuracy, 2)))\n",
    "    else:\n",
    "        print('Min-max scaling works better by {}%'.format(round(minmax_accuracy - standard_accuracy, 2)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WE CHOOSE MINMAX_SCALING BECAUSE THE SUM OF ACCURACY DIFFERENCE MARGINS FAVOURS MINMAX_SCALING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***HYPERPARAMETER TUNING***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "best_params = []\n",
    "accuracies = []\n",
    "\n",
    "for i in models:\n",
    "    model = GridSearchCV(models[i], hyper_params[i], cv = 5, scoring = 'accuracy')\n",
    "    model.fit(np.append(mm_X_train, mm_X_test, axis=0), np.append(Y_train, Y_test, axis=0))\n",
    "    best_params.append(model.best_params_)\n",
    "    accuracies.append(model.best_score_)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "\tBest parameters: {'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "\tAccuracy: 75.98\n",
      "\n",
      "DecisionTree\n",
      "\tBest parameters: {'max_depth': 20, 'max_features': None}\n",
      "\tAccuracy: 53.75\n",
      "\n",
      "RandomForest\n",
      "\tBest parameters: {'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 75}\n",
      "\tAccuracy: 72.87\n",
      "\n",
      "KNN_Classifier\n",
      "\tBest parameters: {'algorithm': 'ball_tree', 'metric': 'manhattan', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "\tAccuracy: 69.97\n",
      "\n",
      "SVM_Classifier\n",
      "\tBest parameters: {'C': 10, 'degree': 2, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "\tAccuracy: 75.27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(best_params)):\n",
    "    print(list(models.keys())[i])\n",
    "    print('\\tBest parameters:', best_params[i])\n",
    "    print('\\tAccuracy:', round(accuracies[i]*100, 2))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING AN **A**RTIFICIAL-**N**EURAL-**N**ETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 2.2973 - accuracy: 0.1171 - val_loss: 2.2769 - val_accuracy: 0.1914\n",
      "Epoch 2/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 2.2553 - accuracy: 0.2018 - val_loss: 2.2186 - val_accuracy: 0.1943\n",
      "Epoch 3/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 2.1906 - accuracy: 0.2096 - val_loss: 2.1295 - val_accuracy: 0.2029\n",
      "Epoch 4/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 2.0850 - accuracy: 0.2558 - val_loss: 2.0122 - val_accuracy: 0.2714\n",
      "Epoch 5/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 1.9738 - accuracy: 0.2542 - val_loss: 1.8911 - val_accuracy: 0.2771\n",
      "Epoch 6/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 1.8476 - accuracy: 0.2743 - val_loss: 1.8153 - val_accuracy: 0.2800\n",
      "Epoch 7/150\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 1.7375 - accuracy: 0.2835 - val_loss: 1.7164 - val_accuracy: 0.2943\n",
      "Epoch 8/150\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 1.6678 - accuracy: 0.2666 - val_loss: 1.6885 - val_accuracy: 0.2829\n",
      "Epoch 9/150\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 1.6223 - accuracy: 0.3082 - val_loss: 1.6840 - val_accuracy: 0.3000\n",
      "Epoch 10/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 1.5570 - accuracy: 0.3328 - val_loss: 1.6985 - val_accuracy: 0.2714\n",
      "Epoch 11/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 1.5505 - accuracy: 0.3374 - val_loss: 1.7392 - val_accuracy: 0.2657\n",
      "Epoch 12/150\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 1.5780 - accuracy: 0.3328 - val_loss: 1.6593 - val_accuracy: 0.3171\n",
      "Epoch 13/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 1.5163 - accuracy: 0.3529 - val_loss: 1.5845 - val_accuracy: 0.3457\n",
      "Epoch 14/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 1.4831 - accuracy: 0.3482 - val_loss: 1.5491 - val_accuracy: 0.3800\n",
      "Epoch 15/150\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 1.4247 - accuracy: 0.3867 - val_loss: 1.5776 - val_accuracy: 0.3171\n",
      "Epoch 16/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 1.4137 - accuracy: 0.3713 - val_loss: 1.5600 - val_accuracy: 0.3829\n",
      "Epoch 17/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 1.4195 - accuracy: 0.4022 - val_loss: 1.6476 - val_accuracy: 0.2800\n",
      "Epoch 18/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 1.3904 - accuracy: 0.4191 - val_loss: 1.5636 - val_accuracy: 0.4000\n",
      "Epoch 19/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 1.3130 - accuracy: 0.4931 - val_loss: 1.5847 - val_accuracy: 0.4114\n",
      "Epoch 20/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 1.3104 - accuracy: 0.4915 - val_loss: 1.5041 - val_accuracy: 0.4171\n",
      "Epoch 21/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 1.2513 - accuracy: 0.4992 - val_loss: 1.4141 - val_accuracy: 0.4514\n",
      "Epoch 22/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 1.1923 - accuracy: 0.4992 - val_loss: 1.3905 - val_accuracy: 0.4914\n",
      "Epoch 23/150\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 1.1460 - accuracy: 0.5655 - val_loss: 1.4793 - val_accuracy: 0.4771\n",
      "Epoch 24/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 1.1527 - accuracy: 0.5316 - val_loss: 1.3960 - val_accuracy: 0.4943\n",
      "Epoch 25/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 1.0092 - accuracy: 0.6071 - val_loss: 1.3328 - val_accuracy: 0.5457\n",
      "Epoch 26/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.9982 - accuracy: 0.6117 - val_loss: 1.3084 - val_accuracy: 0.5429\n",
      "Epoch 27/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.9041 - accuracy: 0.6718 - val_loss: 1.3858 - val_accuracy: 0.5371\n",
      "Epoch 28/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.8536 - accuracy: 0.6641 - val_loss: 1.3423 - val_accuracy: 0.5486\n",
      "Epoch 29/150\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.8932 - accuracy: 0.6441 - val_loss: 1.4813 - val_accuracy: 0.4943\n",
      "Epoch 30/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.8329 - accuracy: 0.6471 - val_loss: 1.3315 - val_accuracy: 0.5829\n",
      "Epoch 31/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.7164 - accuracy: 0.7257 - val_loss: 1.5081 - val_accuracy: 0.5114\n",
      "Epoch 32/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.8221 - accuracy: 0.6687 - val_loss: 1.3502 - val_accuracy: 0.5800\n",
      "Epoch 33/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.7054 - accuracy: 0.7288 - val_loss: 1.4672 - val_accuracy: 0.5800\n",
      "Epoch 34/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.6761 - accuracy: 0.7257 - val_loss: 1.2382 - val_accuracy: 0.6114\n",
      "Epoch 35/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.5983 - accuracy: 0.7797 - val_loss: 1.4470 - val_accuracy: 0.5857\n",
      "Epoch 36/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.5626 - accuracy: 0.7750 - val_loss: 1.4989 - val_accuracy: 0.5857\n",
      "Epoch 37/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.5791 - accuracy: 0.7951 - val_loss: 1.5691 - val_accuracy: 0.5771\n",
      "Epoch 38/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.5551 - accuracy: 0.8012 - val_loss: 1.3871 - val_accuracy: 0.5857\n",
      "Epoch 39/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.5138 - accuracy: 0.8074 - val_loss: 1.4679 - val_accuracy: 0.6286\n",
      "Epoch 40/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.4651 - accuracy: 0.8228 - val_loss: 1.4530 - val_accuracy: 0.6371\n",
      "Epoch 41/150\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4239 - accuracy: 0.8521 - val_loss: 1.5143 - val_accuracy: 0.6314\n",
      "Epoch 42/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4201 - accuracy: 0.8536 - val_loss: 1.5976 - val_accuracy: 0.5886\n",
      "Epoch 43/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.5596 - accuracy: 0.7766 - val_loss: 1.4566 - val_accuracy: 0.5857\n",
      "Epoch 44/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.7296 - accuracy: 0.7180 - val_loss: 1.4872 - val_accuracy: 0.6257\n",
      "Epoch 45/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4866 - accuracy: 0.8182 - val_loss: 1.3878 - val_accuracy: 0.6343\n",
      "Epoch 46/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4485 - accuracy: 0.8428 - val_loss: 1.3904 - val_accuracy: 0.6400\n",
      "Epoch 47/150\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.3821 - accuracy: 0.8475 - val_loss: 1.5033 - val_accuracy: 0.6257\n",
      "Epoch 48/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.3829 - accuracy: 0.8829 - val_loss: 1.5076 - val_accuracy: 0.6200\n",
      "Epoch 49/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3412 - accuracy: 0.8783 - val_loss: 1.4703 - val_accuracy: 0.6400\n",
      "Epoch 50/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.3279 - accuracy: 0.8675 - val_loss: 1.5769 - val_accuracy: 0.6371\n",
      "Epoch 51/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.4120 - accuracy: 0.8428 - val_loss: 1.5806 - val_accuracy: 0.6229\n",
      "Epoch 52/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3334 - accuracy: 0.8798 - val_loss: 1.5400 - val_accuracy: 0.6514\n",
      "Epoch 53/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.2813 - accuracy: 0.9168 - val_loss: 1.5486 - val_accuracy: 0.6629\n",
      "Epoch 54/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.2892 - accuracy: 0.9045 - val_loss: 1.5830 - val_accuracy: 0.6486\n",
      "Epoch 55/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.2703 - accuracy: 0.9106 - val_loss: 1.7906 - val_accuracy: 0.6686\n",
      "Epoch 56/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.3416 - accuracy: 0.8921 - val_loss: 1.6062 - val_accuracy: 0.6457\n",
      "Epoch 57/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3181 - accuracy: 0.8921 - val_loss: 1.7452 - val_accuracy: 0.6314\n",
      "Epoch 58/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.4238 - accuracy: 0.8475 - val_loss: 1.7823 - val_accuracy: 0.6114\n",
      "Epoch 59/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3785 - accuracy: 0.8721 - val_loss: 1.7113 - val_accuracy: 0.6200\n",
      "Epoch 60/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.3194 - accuracy: 0.8937 - val_loss: 1.5349 - val_accuracy: 0.6486\n",
      "Epoch 61/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.2635 - accuracy: 0.9260 - val_loss: 1.8643 - val_accuracy: 0.6429\n",
      "Epoch 62/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.2335 - accuracy: 0.9384 - val_loss: 1.5887 - val_accuracy: 0.6429\n",
      "Epoch 63/150\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.2395 - accuracy: 0.9307 - val_loss: 1.7029 - val_accuracy: 0.6857\n",
      "Epoch 64/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.2304 - accuracy: 0.9183 - val_loss: 1.6668 - val_accuracy: 0.6714\n",
      "Epoch 65/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.2485 - accuracy: 0.9153 - val_loss: 1.7188 - val_accuracy: 0.6514\n",
      "Epoch 66/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.2209 - accuracy: 0.9353 - val_loss: 1.7117 - val_accuracy: 0.6743\n",
      "Epoch 67/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1952 - accuracy: 0.9399 - val_loss: 1.5782 - val_accuracy: 0.6771\n",
      "Epoch 68/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.1619 - accuracy: 0.9615 - val_loss: 1.7279 - val_accuracy: 0.6629\n",
      "Epoch 69/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.2711 - accuracy: 0.9014 - val_loss: 1.4898 - val_accuracy: 0.7000\n",
      "Epoch 70/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.1775 - accuracy: 0.9538 - val_loss: 1.5947 - val_accuracy: 0.6771\n",
      "Epoch 71/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.1324 - accuracy: 0.9692 - val_loss: 1.6187 - val_accuracy: 0.6971\n",
      "Epoch 72/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1172 - accuracy: 0.9723 - val_loss: 1.5621 - val_accuracy: 0.6886\n",
      "Epoch 73/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0959 - accuracy: 0.9784 - val_loss: 1.6356 - val_accuracy: 0.7057\n",
      "Epoch 74/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0879 - accuracy: 0.9815 - val_loss: 1.6898 - val_accuracy: 0.7086\n",
      "Epoch 75/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0788 - accuracy: 0.9831 - val_loss: 1.6659 - val_accuracy: 0.7000\n",
      "Epoch 76/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0767 - accuracy: 0.9815 - val_loss: 1.5790 - val_accuracy: 0.6943\n",
      "Epoch 77/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0809 - accuracy: 0.9815 - val_loss: 1.7795 - val_accuracy: 0.6886\n",
      "Epoch 78/150\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0762 - accuracy: 0.9831 - val_loss: 1.7219 - val_accuracy: 0.7029\n",
      "Epoch 79/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0711 - accuracy: 0.9831 - val_loss: 1.7994 - val_accuracy: 0.7086\n",
      "Epoch 80/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0675 - accuracy: 0.9831 - val_loss: 1.7339 - val_accuracy: 0.7143\n",
      "Epoch 81/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0641 - accuracy: 0.9831 - val_loss: 1.7948 - val_accuracy: 0.6971\n",
      "Epoch 82/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0609 - accuracy: 0.9846 - val_loss: 1.7414 - val_accuracy: 0.7114\n",
      "Epoch 83/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0641 - accuracy: 0.9831 - val_loss: 1.7802 - val_accuracy: 0.7086\n",
      "Epoch 84/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0558 - accuracy: 0.9846 - val_loss: 1.8485 - val_accuracy: 0.7029\n",
      "Epoch 85/150\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0531 - accuracy: 0.9846 - val_loss: 1.8250 - val_accuracy: 0.6914\n",
      "Epoch 86/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0539 - accuracy: 0.9831 - val_loss: 1.9417 - val_accuracy: 0.6829\n",
      "Epoch 87/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0701 - accuracy: 0.9784 - val_loss: 1.8482 - val_accuracy: 0.6886\n",
      "Epoch 88/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0779 - accuracy: 0.9753 - val_loss: 2.2521 - val_accuracy: 0.6486\n",
      "Epoch 89/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3183 - accuracy: 0.9122 - val_loss: 1.6070 - val_accuracy: 0.6886\n",
      "Epoch 90/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.2037 - accuracy: 0.9399 - val_loss: 1.9201 - val_accuracy: 0.6543\n",
      "Epoch 91/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0965 - accuracy: 0.9738 - val_loss: 1.7884 - val_accuracy: 0.7000\n",
      "Epoch 92/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0666 - accuracy: 0.9831 - val_loss: 1.7758 - val_accuracy: 0.7171\n",
      "Epoch 93/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0647 - accuracy: 0.9831 - val_loss: 1.8201 - val_accuracy: 0.6971\n",
      "Epoch 94/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0499 - accuracy: 0.9831 - val_loss: 1.8485 - val_accuracy: 0.7029\n",
      "Epoch 95/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0477 - accuracy: 0.9861 - val_loss: 1.8865 - val_accuracy: 0.7143\n",
      "Epoch 96/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0480 - accuracy: 0.9861 - val_loss: 1.8483 - val_accuracy: 0.7200\n",
      "Epoch 97/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0524 - accuracy: 0.9861 - val_loss: 1.9531 - val_accuracy: 0.7086\n",
      "Epoch 98/150\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0524 - accuracy: 0.9861 - val_loss: 1.9469 - val_accuracy: 0.7000\n",
      "Epoch 99/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0454 - accuracy: 0.9861 - val_loss: 2.0227 - val_accuracy: 0.7029\n",
      "Epoch 100/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0854 - accuracy: 0.9738 - val_loss: 1.9549 - val_accuracy: 0.7086\n",
      "Epoch 101/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.1709 - accuracy: 0.9646 - val_loss: 3.1160 - val_accuracy: 0.5571\n",
      "Epoch 102/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 1.2060 - accuracy: 0.7211 - val_loss: 2.1580 - val_accuracy: 0.5429\n",
      "Epoch 103/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.5788 - accuracy: 0.7797 - val_loss: 1.4766 - val_accuracy: 0.6400\n",
      "Epoch 104/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.2765 - accuracy: 0.9153 - val_loss: 1.6067 - val_accuracy: 0.6800\n",
      "Epoch 105/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.2040 - accuracy: 0.9337 - val_loss: 1.6856 - val_accuracy: 0.6343\n",
      "Epoch 106/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1829 - accuracy: 0.9522 - val_loss: 1.5431 - val_accuracy: 0.6886\n",
      "Epoch 107/150\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1713 - accuracy: 0.9507 - val_loss: 1.6614 - val_accuracy: 0.6771\n",
      "Epoch 108/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0904 - accuracy: 0.9692 - val_loss: 1.6880 - val_accuracy: 0.6943\n",
      "Epoch 109/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.1677 - accuracy: 0.9522 - val_loss: 1.6165 - val_accuracy: 0.6886\n",
      "Epoch 110/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0829 - accuracy: 0.9784 - val_loss: 1.8132 - val_accuracy: 0.6743\n",
      "Epoch 111/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0702 - accuracy: 0.9800 - val_loss: 1.8147 - val_accuracy: 0.6743\n",
      "Epoch 112/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0611 - accuracy: 0.9815 - val_loss: 1.7001 - val_accuracy: 0.6943\n",
      "Epoch 113/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0474 - accuracy: 0.9877 - val_loss: 1.7350 - val_accuracy: 0.6943\n",
      "Epoch 114/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0528 - accuracy: 0.9831 - val_loss: 1.7934 - val_accuracy: 0.6943\n",
      "Epoch 115/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0506 - accuracy: 0.9861 - val_loss: 1.6673 - val_accuracy: 0.7343\n",
      "Epoch 116/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0628 - accuracy: 0.9831 - val_loss: 1.8667 - val_accuracy: 0.6886\n",
      "Epoch 117/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0557 - accuracy: 0.9815 - val_loss: 1.8144 - val_accuracy: 0.7057\n",
      "Epoch 118/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0567 - accuracy: 0.9815 - val_loss: 1.6093 - val_accuracy: 0.7200\n",
      "Epoch 119/150\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0472 - accuracy: 0.9846 - val_loss: 1.7792 - val_accuracy: 0.7086\n",
      "Epoch 120/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0394 - accuracy: 0.9877 - val_loss: 1.7925 - val_accuracy: 0.7200\n",
      "Epoch 121/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0387 - accuracy: 0.9877 - val_loss: 1.9044 - val_accuracy: 0.6943\n",
      "Epoch 122/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0359 - accuracy: 0.9861 - val_loss: 1.8813 - val_accuracy: 0.7086\n",
      "Epoch 123/150\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0368 - accuracy: 0.9892 - val_loss: 1.8252 - val_accuracy: 0.7143\n",
      "Epoch 124/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0330 - accuracy: 0.9908 - val_loss: 1.8689 - val_accuracy: 0.7143\n",
      "Epoch 125/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0324 - accuracy: 0.9908 - val_loss: 1.8668 - val_accuracy: 0.7114\n",
      "Epoch 126/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0305 - accuracy: 0.9908 - val_loss: 1.8849 - val_accuracy: 0.7143\n",
      "Epoch 127/150\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0295 - accuracy: 0.9908 - val_loss: 1.8724 - val_accuracy: 0.7171\n",
      "Epoch 128/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0331 - accuracy: 0.9892 - val_loss: 1.8618 - val_accuracy: 0.7171\n",
      "Epoch 129/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0511 - accuracy: 0.9831 - val_loss: 2.1401 - val_accuracy: 0.7057\n",
      "Epoch 130/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0450 - accuracy: 0.9877 - val_loss: 2.0043 - val_accuracy: 0.7000\n",
      "Epoch 131/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0576 - accuracy: 0.9800 - val_loss: 1.9916 - val_accuracy: 0.6886\n",
      "Epoch 132/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0347 - accuracy: 0.9908 - val_loss: 1.8209 - val_accuracy: 0.7143\n",
      "Epoch 133/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0584 - accuracy: 0.9800 - val_loss: 2.5302 - val_accuracy: 0.6286\n",
      "Epoch 134/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.2647 - accuracy: 0.9307 - val_loss: 1.6918 - val_accuracy: 0.6771\n",
      "Epoch 135/150\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.1415 - accuracy: 0.9553 - val_loss: 1.8655 - val_accuracy: 0.6829\n",
      "Epoch 136/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.1868 - accuracy: 0.9538 - val_loss: 1.5375 - val_accuracy: 0.7114\n",
      "Epoch 137/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.2570 - accuracy: 0.9476 - val_loss: 2.0242 - val_accuracy: 0.6314\n",
      "Epoch 138/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.2670 - accuracy: 0.9260 - val_loss: 1.5472 - val_accuracy: 0.6743\n",
      "Epoch 139/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4082 - accuracy: 0.8937 - val_loss: 1.5197 - val_accuracy: 0.6971\n",
      "Epoch 140/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.2133 - accuracy: 0.9414 - val_loss: 1.5579 - val_accuracy: 0.6914\n",
      "Epoch 141/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0774 - accuracy: 0.9784 - val_loss: 1.7955 - val_accuracy: 0.6771\n",
      "Epoch 142/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.1095 - accuracy: 0.9661 - val_loss: 1.8335 - val_accuracy: 0.6971\n",
      "Epoch 143/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0804 - accuracy: 0.9738 - val_loss: 1.7789 - val_accuracy: 0.6829\n",
      "Epoch 144/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0526 - accuracy: 0.9831 - val_loss: 1.6778 - val_accuracy: 0.6943\n",
      "Epoch 145/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0408 - accuracy: 0.9892 - val_loss: 1.8082 - val_accuracy: 0.6857\n",
      "Epoch 146/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0388 - accuracy: 0.9861 - val_loss: 1.6994 - val_accuracy: 0.7114\n",
      "Epoch 147/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0310 - accuracy: 0.9923 - val_loss: 2.0059 - val_accuracy: 0.6771\n",
      "Epoch 148/150\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0283 - accuracy: 0.9908 - val_loss: 1.7216 - val_accuracy: 0.7000\n",
      "Epoch 149/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0266 - accuracy: 0.9923 - val_loss: 1.6871 - val_accuracy: 0.7143\n",
      "Epoch 150/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0262 - accuracy: 0.9908 - val_loss: 1.8087 - val_accuracy: 0.6943\n",
      "11/11 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6942857142857143"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "ann_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1024, input_shape = (415,), activation = 'relu'),\n",
    "    tf.keras.layers.Dense(512, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(256, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(128, activation = 'softmax'),\n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(10, activation = 'softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer = 'adam',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "History = ann_model.fit(mm_X_train, Y_train_hotencoded, epochs = 150, validation_data=(mm_X_test, Y_test_hotencoded))\n",
    "\n",
    "Y_predictions = ann_model.predict(mm_X_test)\n",
    "\n",
    "observations = [labels[np.argmax(i)] for i in Y_predictions]\n",
    "accuracy_score(Y_test, observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***CHECKING ACCURACY OF TESTING AND TRAINING DATA THROUGHOUT THE EPOCHS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy = History.history['accuracy']\n",
    "training_loss = History.history['loss']\n",
    "\n",
    "validation_accuracy = History.history['val_accuracy']\n",
    "validation_loss = History.history['val_loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACCURACY COMPARISION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(150)\n",
    "plt.plot(epochs, training_accuracy, color='r', label='train_acc')\n",
    "plt.plot(epochs, validation_accuracy, color='b', label='val_acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy Metric')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOSS COMPARISION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABKTElEQVR4nO2dd3gUVffHvyeFJPTeQu9VWkCqggjSFEUpiiIW+KEoguUFLFhexAJ2EGwIIipV5VUQBYMFBAkQeugloRl6CQkp5/fH2XE3yW6ySXZ2Nrvn8zzzzE6/M7t7v3POvfccYmYoiqIogUuQ1QVQFEVRrEWFQFEUJcBRIVAURQlwVAgURVECHBUCRVGUACfE6gLklfLly3OtWrWsLoaiKEqhYtOmTaeZuYKzbYVOCGrVqoWYmBiri6EoilKoIKIjrrapa0hRFCXAUSFQFEUJcFQIFEVRApxC10agKIr/kZqaioSEBCQnJ1tdlEJPeHg4qlWrhtDQULePUSFQFMVyEhISUKJECdSqVQtEZHVxCi3MjDNnziAhIQG1a9d2+zh1DSmKYjnJyckoV66cikABISKUK1cuz5aVCoGiKD6BioBnyM9zVCFQFMUpixYBZ85YXQrFG6gQKIqSjfPngUGDgC+/tLokijdQIVAUJRtJSTK/fNnacniL8+fP48MPP8zzcX369MH58+fzfNzw4cOxePHiPB9nFioEiqJkIyVF5oHSm9OVEKSlpeV43PLly1G6dGmTSuU9tPuooijZMITg6lULLj52LBAb69lztmwJvPuuy80TJkzAgQMH0LJlS4SGhiI8PBxlypRBXFwc9u7di9tvvx3x8fFITk7GE088gZEjRwKwxz67fPkyevfujc6dO2PdunWIjIzE999/j4iIiFyLtnr1ajz99NNIS0tD27ZtMXPmTISFhWHChAlYtmwZQkJC0LNnT0ybNg2LFi3Cyy+/jODgYJQqVQq///67Rx6PCoGiKNkINIvg9ddfx44dOxAbG4s1a9agb9++2LFjx7998WfPno2yZcvi6tWraNu2Le68806UK1cu0zn27duHr7/+Gp988gkGDRqEJUuW4N57783xusnJyRg+fDhWr16NBg0aYNiwYZg5cybuu+8+fPvtt4iLiwMR/et+euWVV7By5UpERkbmyyXlCtOEgIjCAfwOIMx2ncXM/GKWfcIAfAGgDYAzAAYz82GzyqQointYahHk8ObuLdq1a5dpQNb777+Pb7/9FgAQHx+Pffv2ZROC2rVro2XLlgCANm3a4PDhw7leZ8+ePahduzYaNGgAALj//vsxY8YMPPbYYwgPD8dDDz2Efv36oV+/fgCATp06Yfjw4Rg0aBAGDBjggTsVzGwjSAFwEzO3ANASQC8iap9ln4cAnGPmegDeAfCGieVRFMVNAs0iyEqxYsX+/bxmzRqsWrUKf/31F7Zu3YpWrVo5HbAVFhb27+fg4OBc2xdyIiQkBH///Tfuuusu/PDDD+jVqxcAYNasWZg8eTLi4+PRpk0bnPFQ/17TLAJmZgBGn4NQ28RZdusP4CXb58UAphMR2Y5VFMUiLLUILKBEiRK4dOmS020XLlxAmTJlULRoUcTFxWH9+vUeu27Dhg1x+PBh7N+/H/Xq1cO8efNw44034vLly0hKSkKfPn3QqVMn1KlTBwBw4MABXH/99bj++uuxYsUKxMfHZ7NM8oOpbQREFAxgE4B6AGYw84Ysu0QCiAcAZk4jogsAygE4neU8IwGMBIAaNWqYWWRFURB4FkG5cuXQqVMnNGvWDBEREahUqdK/23r16oVZs2ahcePGaNiwIdq3z+rYyD/h4eH4/PPPMXDgwH8bi0eNGoWzZ8+if//+SE5OBjPj7bffBgA888wz2LdvH5gZ3bt3R4sWLTxSDvLGyzcRlQbwLYDHmXmHw/odAHoxc4Jt+QCA65n5tNMTAYiKimLNUKYo5rJ0KXDnnUDXrkB0tPnX2717Nxo3bmz+hQIEZ8+TiDYxc5Sz/b0yjoCZzwOIBtAry6ZjAKoDABGFACgFaTRWFMVCAs01FOiYJgREVMFmCYCIIgD0ABCXZbdlAO63fb4LwK/aPqAo1hNoriGzGD16NFq2bJlp+vzzz60uVjbMbCOoAmCurZ0gCMBCZv6BiF4BEMPMywB8BmAeEe0HcBbAEBPLoyiKm6hF4BlmzJhhdRHcwsxeQ9sAtHKyfpLD52QAA80qg6Io+UMtgsBCYw0pipINtQgCCxUCRVGyoRZBYKFCoChKNtQiCCxUCBRFyYYhBGlpMinZKV68uMtthw8fRrNmzbxYmoKhQqAoSjYMIQDUPRQIaBhqRVGykVUIcnj59TgWpCMAIDkJqlevjtGjRwMAXnrpJYSEhCA6Ohrnzp1DamoqJk+ejP79++fp2snJyXjkkUcQExODkJAQvP322+jWrRt27tyJBx54ANeuXUNGRgaWLFmCqlWrYtCgQUhISEB6ejpeeOEFDB48OH83nQdUCBRFyYajFRAo7QSDBw/G2LFj/xWChQsXYuXKlRgzZgxKliyJ06dPo3379rjttttARG6fd8aMGSAibN++HXFxcejZsyf27t2LWbNm4YknnsDQoUNx7do1pKenY/ny5ahatSp+/PFHABLwzhuoECiKkg0rXUNWpSNo1aoV/vnnHxw/fhyJiYkoU6YMKleujHHjxuH3339HUFAQjh07hlOnTqFy5cpun/fPP//E448/DgBo1KgRatasib1796JDhw549dVXkZCQgAEDBqB+/fpo3rw5nnrqKYwfPx79+vVDly5dzLrdTGgbgaIo2XAUgkCxCABg4MCBWLx4MRYsWIDBgwdj/vz5SExMxKZNmxAbG4tKlSo5zUWQH+655x4sW7YMERER6NOnD3799Vc0aNAAmzdvRvPmzfH888/jlVde8ci1ckMtAkVRshGojcWDBw/GiBEjcPr0afz2229YuHAhKlasiNDQUERHR+PIkSN5PmeXLl0wf/583HTTTdi7dy+OHj2Khg0b4uDBg6hTpw7GjBmDo0ePYtu2bWjUqBHKli2Le++9F6VLl8ann35qwl1mR4VAUZRsBKpF0LRpU1y6dAmRkZGoUqUKhg4diltvvRXNmzdHVFQUGjVqlOdzPvroo3jkkUfQvHlzhISEYM6cOQgLC8PChQsxb948hIaGonLlynj22WexceNGPPPMMwgKCkJoaChmzpxpwl1mxyv5CDyJ5iNQFPPp0gWIiRFrYMUKoFfWAPIeRvMReBafzEegKErhIiUFKFVKPgeSayhQUdeQoijZSEkBSpcGTp0KLNdQXtm+fTvuu+++TOvCwsKwYUPWrLy+jQqBoijZsMIiYOY89c/3BZo3b45YT49+KyD5cfera0hRlGwYFgHgHYsgPDwcZ86cyVclpthhZpw5cwbh4eF5Ok4tAkVRsuFti6BatWpISEhAYmKi+Rfzc8LDw1GtWrU8HaNCoChKNrxtEYSGhqJ27drmX0hxirqGFEXJRkqKBJoLCtJeQ4GACoGiKNlISQHCw2XSXkP+jwqBoiiZyMiQZDRhYUBEhFoEgYAKgaIomTDCS4SFqUUQKJgmBERUnYiiiWgXEe0koiec7NOViC4QUaxtmmRWeRRFcQ9HIVCLIDAws9dQGoCnmHkzEZUAsImIfmHmXVn2+4OZ+5lYDkVR8oBaBHbGjweOHwfmzbO6JOZimhAw8wkAJ2yfLxHRbgCRALIKgaIoPoRaBHY2bRIh8He80kZARLUAtALgLABHByLaSkQriKipN8qjKIpr1CKwc/lyYNy/6UJARMUBLAEwlpkvZtm8GUBNZm4B4AMA37k4x0giiiGiGB15qCjmktUiCISK0BVXrgBJSVaXwnxMFQIiCoWIwHxmXpp1OzNfZObLts/LAYQSUXkn+33MzFHMHFWhQgUzi6woAU9WiyCQXUOXL6sQFAiSMIKfAdjNzG+72KeybT8QUTtbec6YVSZFUXJHLQI7hkXg77HwzOw11AnAfQC2E1Gsbd2zAGoAADPPAnAXgEeIKA3AVQBDWMMPKoqlqEVg5/JlGWCXmgoUKWJ1aczDzF5DfwLIMbg4M08HMN2sMiiKknfUIhDS0+33npTk30KgI4sVRcmEWgSCY9uAv7cTqBAoipIJtQiEK1fsn1UIFEUJKLIKQVqaTIHG5cv2z/4uhioEiqJkIqtrCAhM95BaBIqiBCxZLQIgMIXA0SJQIVAUJaBwZhH4u2vEGWoR+CPMwObNVpdCUXweQwjCw9UiMPB3IQwcIfj8c6S3aQesXGl1SRTFpzGEoEgRtQgM1CLwE5aXvgf1Qg/j1N1jgfh4q4ujKD5LSoqIAJFaBAYqBH5CvWbhSOBIvHzpSWDIEBkzriiFjCtXALMD8KakSPsAoBaBgQqBn9CgAfB//0f4OOMh7Fl3Gpg71+oiKUqeee45oHt3c6+RnGwXAsMiCEQh0DYCP2XSJKBoMcLE0rOAKVPUKlAKHQcOmO/ZdGYRBKJr6MoVEcLgYLUI/IqKFYHx4wnfnu+GzYdKA/PnW10kRckTp08Dly6ZGxbZUQgC3SIoXhwoWlSFwO949FGgSBHGFxWeBiZPDsyx80qh5fRpiYpp9OwxA7UIhCtXgGLFVAj8kjJlgL59Cd+kDkDagcPATz9ZXSRFcRujofjSJfOuoRaB4GgR+Pv9B5wQAMC99wKnzodjdXg/4IcfrC6OorhFaipw4YJ89pYQBLJFYAhBRIRaBH5Jnz5A6dLA/ApjgR9/9P88dIpfcMYhiatjjxZPE0gWAbPrv7+6hvyc8HDgrruApf90wpWEs8C2bVYXSVFy5fRp+2dvWQRFigChoZn71PsTXbsCEyY436aNxQHAPfcAV1JC8TN6ilWgKD6O40AybwkBIJWhmRaIVTADf/8NfPed8+2OFoG/WkQGASsEnTrJl/xLhaHaTqAUChwtAm+5hgD/FYLTp6XtY+9e4J9/sm/XNoIAoEgRMQtXpXcD1q/P/C9TFB/ECtcQ4L9C4Dgwb+3a7Nu1jSBAuPlmYN/ZcjjC1YEVK6wujqLkiAqBZzl61P75zz8zb2MWIdA2ggCgRw+Zryo5QNsJFJ8nMdHei0ddQwXHsAgaNcouBFevihhoG0EBIaLqRBRNRLuIaCcRPeFkHyKi94loPxFtI6LWZpXHGU2aAFWqAL+Uu1vyFGjsIcWHOX0aiIyUXjxqERSc+Hi5zzvukJxVjj2jjPvVNoKCkwbgKWZuAqA9gNFE1CTLPr0B1LdNIwHMNLE82SAS99DqMy2Qcf4CsG6dNy+vKHni9GmgfHmpnDwtBGlpwLRpYnUEihAcPQpUrw7ccIPc/4YN9m2GKBgWQWqq8/fEbduAd9/1SnFNxTQhYOYTzLzZ9vkSgN0AIrPs1h/AFyysB1CaiKqYVSZn9OgBnL4Yhq0hUeoeUnwaQwhKlPB8xbx4MfDMM8BLLwWOEMTHixB06CAvhStX2geXOVoERYvKZ2fuoTlzgHHjPBuybMEC+whyb+GVNgIiqgWgFYANWTZFAnAMqpuA7GJhKkZs919qjdBupIpPk5hoFwJPWwTTp8v8s89kboSWAPxfCEqVAm68EXjzTaBlS2DNmuwWAeBcCM6dk7mnKu4jRyRv1hdfeOZ87mK6EBBRcQBLAIxl5ov5PMdIIoohophED6dnqloVaNoUWBXcE9i9Gzh40KPnVxRPwGyea2jLFuk++X//B1y7JuucWQT+FIklLQ04dgyoUUOWly0DPvpIwng880z2NgLAeTuBIQTGvKAYDdhHjnjmfO6SqxAQ0R1EVMphuTQR3e7OyYkoFCIC85l5qZNdjgGo7rBczbYuE8z8MTNHMXNUhQoV3Ll0nrj5ZuCPw9WRjDBNbq/4JElJMvipQgXPWQRG5T5jhlR2r70GDBgg27IKAbN/9Zw5cQLIyBCLAJBnOnKkvI3v2GF/w3e0CLwhBMdstZ+306q7YxG8yMz/Gj7MfB7Ai7kdREQE4DMAu5n5bRe7LQMwzNZ7qD2AC8x8wo0yeZQePYDklCD8Wf4OsQsVxUc4dEgMVWMMgafaCDZvBkqWBMqWFTfEvfdKiPaJE8VfXq6cfd/ixWXuT+4ho6I1LAKDli1FcDdvlmXHNgJvCMHx4zJPSPDM+dwlxI19nImFO8d1AnAfgO1EFGtb9yyAGgDAzLMALAfQB8B+AEkAHnDjvB7nxhuBkBBgVaWhuHnNQ/L6Q2RFURQlE/ffL26CxYtl2VOuoYULJQXjwIEiNv/5j6xv0waIiwNq17bv6ygEFSsW7Lq+gjGYrHr1zOtbtpS5MdI4tzaC8+dlXtgtAncq9BgiehvADNvyaACbcjuImf8EkGNtysxsO5+lFC8uPQd+Odoer//zD7BrlzQcKIqFXLD1aE5PB/73P1mXtbF4zhxg5kzgr7+AoDy0+C1bJi9AH3+cfVuDBpmX/dkiyCoEDRuKW8zoSurtNgJDCI4fl+89ONgz580Nd346jwO4BmCBbUqBD1TenqZHD2DL0XI4jXJAdLTVxVEUREdLZQDYK+ysrqE//pAImrt2uX/effvE3XTbbe7t76tCcOiQWC6vvmp/Tu4SHy+9hUqWzLw+NFTeAY1EPDm1EaSm2p/J2bN5L78zDNdQerq0Y3iLXIWAma8w8wSjsZaZJzKz30Un79EDYCYsLzdMhUDxCX7+WSrhfv2AU6dkXYUKsu7aNZmMiuP333M+19q18hvft89uXdx6q3vl8FUhWLIEOHwYeP556fDhqjLeuVNcbBMmyGfAPpjMGYZ7KCxMXMauhMBwCwGetQhK2brmeLOdwKUQENG7tvn/iGhZ1slrJfQS7dqJSTwz6FHgt9+kS4FSKNm5U/zchZ2ffwa6dQPuu0+Wg4OlkihRQpYvXXJPCA4eBPr3B1atElH5+mugefPM7QA54W0hSEgA3nor97f8FSuAZs2A2bMlVtDEibI+KUm6wt51F3DnnUCLFsDSpTJyulkzoHVrCTictaHYwBCCYsVk7thGsHevPEfA80LALELQrp0se7OdICeLYJ5tPg3AW04mvyIoCBg9GlifWA8xZ2pJHzKlUDJiBPDoo1aXIn9s3y7TgQMy9ewJ9O0rlVK5cvI7NYTg8uXMQuCsn/+5c1L5Z2QAn38u7pSYGPfdQoD3hWDOHODpp4FPPnG9z6VL4hbr3Rt44AHgsceATz8Ftm4FnnhCjt21C9i4ERg1Su77+HHgvfdEUE+dAho3dn5uQwiM+3ZsI3juOWDoUFl2rPw9IQTnz4tLqn17WfZqgzEzu5wABEPGAOS4nzenNm3asFmcP89crGg6D8ds5mnTTLuOYi6Rkcy1alldiryTlMRcsSJzcDDzTTdJNt09e2TbyJHM3brJ5wULZNumTTKvVk3m+/ZlPl98PHOzZsyhocy//irrPv+cuVQp5m3b3C/XqVNy/hkzCnqH7nHPPXK90qWZT550vs9338k+xn2dPctctixzzZqyfsKEnK9x+DDzlSvOt50/L+do3FiWr16V5SlTmOvVk88pKcw//SSfQ0Ls340rLl1iXrSIOTXV9T7bt8v5vv6auVgx5rFjcz5nXgEQwy7q1RzbCJg5HUBNIiriBU2ynFKlgGH3B+Frugenv3eSqULxeTIy5G0vISHvDYhWM2eOZMrq1An49VegZk2gfn3Z9uGHdpeEYRHs3SvzwYNl7uge2r9fesIdOSIulG7dZP3w4TImoXlz98tVUIsgJUXe1P/8M3MOAFfs3i1v61eu2Lu1ZmXFCilXp06yXKYM8PLLcr/t2wOvvJLzNWrWtLt8slKqFFCnjv2+w8KkN/k//4iVBshvzLACatbM2SJIT5fvaOBA6eHlCqPHUGSktF9kbSMwc2S3O72GDgJYS0QvENGTxmRekaxl9GgghcMwf20tc2P9KqZw5oyED0hLszew+gL79tl7ojgjLQ2YOlUq7zVrgG++kZ5CxnCW4GB799CsQtC9u/QmMoQgJQUYNEh82n/8YY+nZRDiTqdxByIipBz5FYKRI8Xd0qWLTDlVaBkZ0r5zyy3Ak0/KYLesLhJmEYKbb5ZMgwb/93/A++9LI3JoaP7KavDII9K+AMi9R0RI7yyj7CdO2Cv/OnVyFoJnngGWL5fKfdKkzLmnz56VRvy9e+1uvshIoFq1zPfNLHkTXn+9YPflCneE4ACAH2z7lrBNxc0pjvU0bQo0r3MZSzJuB1avtro4AQ8zMH48EBubfdulS9mjPjp2uXPn7dMbnDghjZTjxslyaqq8ob/2mn2fRYvEjz1hglQ8gwdL+4AzjDfVPXtkHhkpFeyqVSI4zz4r8YM+/1waSgsKUcEGsW3cKG/u48fLd5K1+e3rr4FevUQEjh4VAWvcWNo2AHtPHwA4eVIipB49Ku0DjoSGAo8/LvHDCsrTT0t5DYoWBTY5jJ46ccLeWJyTEKxeDbzzDjBmjESvuXxZejkZ/PSTfG9z5tgtgqpVRTQchSAuTsTCccS3R3HlMzImAAPdWeetycw2AoMXn09jQjqfHPqk6ddSciY+XvymY8ZkXh8XJz7hBx7IvN7w2wLiS7eCS5eYa9cWXy8z8yuvSHmKFJH7+egju295507xSdevz9ykCXN6eu7n379fjm/TRuaJieIzDw623/vo0Z69pypVmB9+OO/HpaTIfT77rP27nDrVvv3CBeYKFWT91q3My5fL599/l/sCmN95R/bdsYM5PFzW9eolz81b1Kgh1zWe8cyZzM88wxwWxvzSS7LOmf//tddk24ULsjxuHDMR865dsjxypGy/7jrmUaPkN83MPGmS7Hftmix/8IHsd+BA/u8B+W0jsDHRzXV+w52DgsEIwnc/hvhXyMVCiPHW6/gWmZgI9OkjZnVW14GjReDtYfoGO3bI2/2TTwIXL0pUy1at5I33lVdkat1aXDyPPSa9UA4dkuBv7owONlxDe/bIW3C5ctI9ND5erIwHHxQ3kyfJbyjq/fvFamvcWNwdTZvKW7DB1Kl2V0l0tLQPALJ/+fJyb0ZX4JUrxb22ZYu4hoz+9t7AaE+4/nqxkAzXUJkyMgGZu5MaHDwo92EMXDOsjIULZf7773K+bdtkNHOkLQh/tWpS9RjuolWrgFq1xPowg5zGEfQmog8ARNrSSRrTHEj2Mb+lWTOgfqULWHK+u3xDLvjrLzFVFfMwhGD7dvu6wYPlD7JggSy//759myEE4eHWuYaMyuzECen6eeyY+IaHDZNujceOST/5V1+Vyu/HH+UeunZ17/yOjbdVq9rbEapUEdfSZ5/Zuzx6ivwKgfEsmthyE/bqJe0WV67Id/jWWxLxs3ZteRa7dknFWb687N+okV0IYmPlfo3und7EeJ5t2sigPmdC4Mw9dPAgULeufblSJaBjR+Dbb6UNKy5OBrsBInCGEBiD3RISREjXrJE2EbPI6f3jOIAYAMmQ2ELGtAzALeYVyXqIgAEDgxGNbjj72bdO91m9Gujc2f4lKuZgVAKJidJr4+RJqTCef14aRO+6SxpVL9oyXZw8KW9fdeu6tgjS0537u7dtE/96QY3A3bulEfP226WnTLVq4u+eOFHe+Hv0kEp/5Ejpzz9hgjROuktEhN1y8IQ/3B3yKwRG6IuGDWV+yy0yIvqXX8RySUsTQezWTd6Od+7M3L8/qxBYIQKA3SJo0UIE12gjyE0IDhzI/hZ/xx3Si8pIPjNqlLztA9mFID5eIqFeuJC90d+TuBQCZt7KzHMB1AOwEMB6Zp7LzEuZ2UMDqn2XO4cVRxpC8dpHZcEXM9caR4/KW0xQkIz+PHTIokIGAHv22ANv7dhhTyt9000yf+opEQEjs9aJE/JHrV7dbhGkp2eu3IcPF7Fo3Bh40SGg+qxZ4lopqJW3e7eMUp86VSyT0aOlp069evICMXeu7BccDHz/feZGY3cgsruHfF0Idu+WSs4YpduliwjZ/feLq2fmTKkou3WTinTDBrv1AIiAnDol38nu3b4lBOfOAaVLuxaC1FT5DTpaBIC8IAAigMWKiZuwb19ZZ3yfNWvKy8THH9sz6Bq/eTNwp42gF4BYAD8BABG19McQE1mJigIeuDUR066NwYM3H0Fiovh4ly2T3gopKfJDDgrKeQSkUjD27LG7THbskJg5YWHy5wGAtm2B664TnzFgF4IaNexC8Oij4u5LTJQ30S+/lDfx4sXFX2/EqDEiTuYlSV1cXPZoJHFx8iZbr56U4Zln7Nu6dpXyFRTDPWS8QZpNXoQgNdXeVXbXrsxv+OHh8gwuXhQBfOghWW+Mc2DObhEA0iU0LU3aWqygaFH5rzdtmlkIcrIIjhyR30ZWi6BuXRnHceGCuIlCQ+1CYHyfxYvLy010NDB5suxvZghwd4TgJQDtAJwHAGaOBeBmlJLCCxHw2fcV8GLNOZizsRkqVpQfQ//+8odYtEgUum9fiXWSmmp1if2PpCT5M91wg/iMt28XIWjbNnMGrdat7U05jhZBYqK4gL75RiqkW2+Vt/N69aR94S1boJS1a6XLonEOd4VgwQKptHr3FrcVIBXgwYP2yqxCBXNCCVttETBLGOus/dpjY6Wiu/VWscT27Mn8hg+IpfTFF5m7Z0ZG2gfPOROCb76RuVUWQb16UmlHRMjv69QpGbOSkxAYv6OsFgEg7iFAniEg/v9XXrGvByRZ0HvviZj06OHZ+8mKO0KQyg4ZymwERFcaIuClGRWwFh3xzuC/MGoU8NVX4ve7xdZKMnKk/CiMiI6K59i3T+aNGskb/caN4i81RpMatGgh38GpUyIElSvbA4otXixvn8OHy4Cgffukd054uAT3KlJEfNNbttjHJBijR3Pi8mVxS9WqJce3bCl//H375I/rKo6Np7BaCKKj5b6XLLGvW75c2s1OnZJeLosWiTBmFYKmTSWQXtbcT4ZV4PjsateWN+Y//5QymNVrJjemTrUHJa5SRUTu4kX3hMBZmYcOle+uf39ZDg0FXngh+1v/mDESA/Ollzx2K05xZ4zhTiK6B0AwEdUHMAbAOnOL5UP07o2OnV5DxxW95JWxZs2sm1G9uvg6jXyvrli/XnqMGCMWlZwxGgkNIZg+XZY7dsy833XXyXztWrEiDNcQIG674GAZ1HPLLeKqMQZqGWLwxx/2CrVECfcsgilT5Ltct07eEtu1E4G5/nrZbrYQGK4hbwsBs1TgH30k62Nj5ZlHREijZ506Ig5t20r3WcD9ZzFmjPSqqVbNvi4kRCyFXbtE8POSfMeTENlHZDu69sqUkd9RRET2MNgHDojl6uw7atDAPoAsN264IX9lzgvuJqZpCklI8zWAiwDGmlgm3yIoCJg3T/4Bw4ZlC2ATHCx/gFWrck8OMmqUmHsXstpXilP27JE/YP36IgQGroRg5UqZG64hQLr4Xn+9NOoNGZI9dk2XLjJiNDpajmndOnchOHRI3ErDhklIiJYtpVfQ/PnSjkGUPcuXp7HCIkhLkx4/p05JWOcmTWRdTIx8V/Hx4nqrX18sZaMrr7tC0LSpuEeyWgqGe8gqt1BWHIWgdGmZlynj3CKoXds68coL7iSmSWLm55i5LUtimueYOYeoKX5I7drABx+ILTxjRrbNI0aI8htvrM7Ytk26jCUn2/2dSs7s2SMGWESEPUhaw4b2PuYG5ctLhWgMVKpSJfNbZa9erq/RpYtUZj/8IIJRp05219Aff0jFZnRRffddeS+YMsW+z7BhUkF+8knOAc08hRUWASBWweefyzMzsqb99Zc0wgN2a+vxx+UNukoVe2WZX3xZCAy3kCshsMqVlVdyGlCWLRmNPyemyZVhw6R1+LXXsmWxrlABuPtuaQBz9bY/b578MerWlT9SYScx0Xn8H08SF2fvf26kkM7aPmBw3XX2XkJVqogwV64sy0Z7jjM6dpQ3UGYRgrp1patiUpL4+l97TXq5fPKJVPwXL8r3N2hQ5h47ffrIKNiTJ813CwFSuRYrlj3VolkYQnDpksT979pVvosGDcQ99vPP8uyMZDfVq4traMiQgl/bsAbbtCn4uTyB8bsCXAsBs7xQOGso9kVyaiPoACAe4g7agFwS0fs9RDI8tGtX6df12GP2bampePzRIMyZE4zPPrP7Ro3GRyJxG/TpI70EnnpK3EjnzsnoyoEDvX43Beb//k/6xJ85k/dolgZXrkjlfeWK/MkdXQLMEmSrc2dZLlVKKiBjOSstWmS2CACpjFJTc65ASpWSY2Njxc9v+G0PHZLG6WeflcqMWdoZUlKkMhw7NvN5ihSRl4Hp0+1vsGYydqxYOlndKGZhCMGOHVLBGQH0OnSQfu7JyeL2dOSNNzxz7YEDpe3Aqq6jWYmIkN/NhQuZhcBxJPuZM/I7KSwWQU7B5oIhYwjmAtgCYDKApq7299bkjaBzOdKli2QCSU6W5Y0bJSLXsGHcvbsExVq7ljkhQQJJRUZKwDSAefFiSfIREsLcsKGsI2I+csTaW3Lkp5+Y163LeZ+TJ+UeAObNm/N3na1bJWGKESQtayKR55+X9V9+6d755s+X/cPCmDMyZN033zDPnp37sePGSUC4y5eZ16+X83z/PXPfvhI8LiNDvs+ICNnWsaPz82zcKNvnzHGvzIWJH3+Uexs1Subbt8v6WbPs3+GSJdaW0Zs0aiT3fPSoLA8bJoHpDIzf0bJl1pTPGcgh6JxblS+AMADDASQCeMydY8yaLBeCn3+Wx9a7t9RWERH/1mj/rN7G9eszlynDXL06c4kS9giRpUvbtWPAABGABx+U+YsvWnpH/3LuHHPx4q4rOoNp0+x//unT83et55+XSI5ffCF/IoB56VKJ4PjGG7L88MP2Sj03jOxONWvmvSxnzzL//bd8NiJeTp4souKYJerFFznXqKYbN9ojRvoTv/0m916jBnO5cvYoqdu2yfqgIPn9BArdusl9X7woy088If93A0Mgd+ywpHhOybcQ2ARgAIBFADYCeAFAZE7HOBw7G8A/AHa42N4VwAXIqOVYAJPcOa/lQpCRIa+QRn7Adu0kJnLp0sy33soHDzJXrizTli2y+9KlzCtX2k9x7pwcwsx8yy1yqpxS2HkLowIuWdJ1BZyRIeGSr7+euWpVSSuYH1q0YL7hBvmcnCyPsWhRSaMIMN91F3Namvvnu3ZN3urbt89feQwyMuQPbaQ8NFIhMktI5e++cy9UtL9hpMUEmO+4w74+LU2eV0Gfe2HjnnvkRcb4nxjhphculMq/RAnmVq18439tkC8hAPAFgM02l1AzV/vlcPwNAFrnIgQ/5PW8lguBI6dP22uFyZPlca5fz4mJ7r8dLVkih/3vf6aV0i1SUqRiN9w1hw87388weT/+WCrr/OQGPnpUzvHmm/Z18fGSp/fhh+XPlJ+36m7dmEeMyPtxWWnRwm7F+ePbfX7Ys8cuBEZ+AIMvv2SOjraiVNbxySeSE8HgzBnmTp3k+ZQvLy+ChtvIV8ivEGQAuGSbLjpMlwBcdHVclnPU8mshcOTSJcmw0ayZCISbXLvGXKkS8223eb5IGRnMr76aPam5M+bOlV+D4Zv/4Qfn+91/v3jDLlxgfvtt2ffYMdfnTU5m/uor5pdflnNfvMj84Ydy3O7d+bqtHK/liYp7wAApX36tHX/k2DG7EOS3XcjfuXqV+e67JfH8+vVWlyY7BW4jyO/khhCcAbAVwAp3G6J9VgiYmVetEsdyVFSe0ieNHy8+1pMnPVscI5PV00/nvF9KijR+NWsmlgwgpm5W9uwRc/iJJ2TZsA4WL5aGVmeCM306/9soTiRNKz17Mtet677/39s8/bSU+ZtvrC6J73DhgjyTUqXy5rILRJKSrC6Bc3ISAivHvG0GUJOZWwD4AMB3rnYkopFEFENEMYmOmZ99je7dZXz91q3Z+9LlwH33SZ91I2uRQWysxNtPSnLvPOfOSVfJjRtl2Qii5phr1RnvvCN99qdMkf7pNWrYE8FkZNhDOL/4ovTPn2jLT9eqlSwvWybdOps1A06fznzu5cslYFdSkoThWLFC+pzfeqv3uj7mlS5dZFBYTgPRAg3HMNJmBNHzJzydFMgruFIIT0zIwSJwsu9hAOVz28+nLQKDN9+U16dVq9w+pEULaYB15N575TRz57p3jqVLZf+JE2XZyKVasqQ0ZaSlyXU++sh+zKFD4uq5/Xb7uj59mJs3l8933y2uK+Mt2Ti3geEXNbqTOnbXvHpVzv344/Z1Tz0l+/32m3v3pPgOgwdLY7lSOIGPuoYqAyDb53YAjhrLOU2FQgiuXpV+dq1bu93FxNAOw71y6ZL0ogGYb7zRvcsalfVNN8my4esGxK1j9HO/+277MQMGyHUcxzKMHy+NxgcPisvK6CBVqpR0tXRkyhTpIREdLT1t+vWzbzN62v74o31dRoZ7bRaKoniWnIQgV9cQERUjoiDb5wZEdBsRhbpx3NcA/gLQkIgSiOghIhpFRKNsu9wFYAcRbQXwPoAhtsIWfsLDJf3Q5s2SrMCN2xoyRFwlX30ly999J+6UPn0kDO3+/blfdu1amW/cKLHxtm61Bz+LiRGXDGA/V0aGuGoefNAerROQuD6pqeICysiQfKmxsVIOYySlwfjxEou/a1eJvvrzz/Y0kCtWiOvIMRcvkbiKFEXxIVwphDFB8hQXBRAJcd8sAjA/t+PMmgqFRcAslkBUlLwSN2okr8o1a8rI5OPHnR5y443M9epJz5pbbpGumfHx8lb+3HM5X+7qVelHHxkpl9ywQeaTJslo53Hj5PwAc9mycsyRI7I8a1bmc23darckund3/5b/+IMzNbI2biwNw4qiWA8K2FhMzJwEGVj2ITMPhISlVnIiKEhCMs6cKcFvDh2SqGabN0vLqpPsJ+PGScTCVq3k0KFDJYpmr17AnDnZImBnIiZGQgQ//rgsGzl827SR861ZI8HBSpaUuOlnz0p0T8Ae2M2gUSN7/KARI9y/5Q4dJCbMkiWSoGX3bm1wVZTCgFtCQEQdAAwFYEujDO034A6lS0sSgl9/lWhdCxZI4PsLFyRerxGVzkb//rI5OVlcMkOHyvoRIyQYWtZeRSdOSK+inTvtSd0feEAqe8PFdN11IgZbtoi7Z/hwWX/ggGshKFJEXErlytkTbbtDcLDsv2iR3SXVu7f7xyuKYg3uxI0cC2AigG+ZeScR1QEQbWqp/Jm2bSWm8YABErbRyFVn44YbpNtnXJw9nPFtt0nXzJdflvDHRve96dPl7XvXLgmJ3KCBpLpr21Yig5YsKd0go6Jk/4gI4P77gfffl3aCuDhJcOIYVtdg6lRxDjnmBnaHCROAsmVFAxs18k4kTkVRCogrn5GzCWJBlMzLMZ6eCk0bQU6kpoozPw8O9MWLxf8+b54sp6QwV6wozQ9Esu2BB2Tbs8/KcufOsrxjB/8bJy8pST7/97/MN98szRiKovg/KGCvoa+IqCQRFQOwA8AuInrGXHnyc0JCJKD/zz/bM7Tnwh13SNz8l1+WmPhLl0pvnXfekbdwwJ60pV07mRspHBs1Atq3F2sgIkKsh/37xTWU1S2kKErg4U4bQRNmvgjgdkgoiNoA7jOzUAHBww+LILz3nrQZ5NLFNChIeqTu3y+jO6dOlaQXPXuKOHzxBXDPPbJvhw6SKrFLF1kODpZ0goMHy3K9etK1ND5eXTeKorgnBKG2cQO3A1jGzKkA/KO/v5VUqSKv+TNmiEO9RQtJ1ZUDfftKm8CePdL5aNQoEYjQUAlTYQxtr1hRMp8ZFX9W6ta1p5lUi0BRFHeE4CPI+IFiAH4nopqQKKRKQfnwQ2DuXAnis327+HlyYcAAEYFnnxXvkitKlXIdy8dxQJcKgaIoRoiHvB1EFMLMabnv6XmioqI4JibGikubyx13SFefAweAChVMvdSiRdL7iEiMkEIZJEtRlDxBRJuYOcrZNncai0sR0dtG9E8iegtiHSieZMoUqZUnTzb9UoZFUKOGioCiKO65hmZDktEMsk0XAXxuZqECksaNgYcekpHIBw+aeqm6dWWubiFFUQD3hKAuM7/IzAdt08sA6phdsIDkpZekJ9ELL5h6mZIlpbdQx46mXkZRlEKCO0JwlYg6GwtE1AnAVfOKFMBUrSoBh776SlqETWTrVuD55029hOIvxMW5nx1JKZS4IwSjAMwgosNEdBjAdAA59FdRCsR//iNBfsaPdyt8dX4pUkQzTSlukJoKtG4NfPSR1SVRTCRXIWDmrSzpJK8DcB0ztwJwk+klC1RKlQImTQJWrbJHjlMUq7h6VaaTJ60uiWIibucsZuaLthHGAPCkSeVRAGD0aHHgjx4NJCRYXRolkElOlrmRbUjxS/KbvN5H0477CcHBEjMiLU2yvN98syQVOHfO6pIpgYYKQUCQXyHQEBNmU7euxIvetUusgthYyS6jKN5EhSAgcCkERHSJiC46mS4BqOrFMgYuDz4of8TYWAko9NdfVpdICTQMIbioUWX8GZeJaZi5hDcLoriACAgPl54bKgSKt1GLICDIr2tI8TYdOkhi4tRUq0uiBBIqBAGBCkFhoUMH+VNu3Wp1SZRAIiVF5ioEfo0KQWGhQweZq3tI8SZqEQQEpgkBEc0mon+IaIeL7URE7xPRfiLaRkStzSqLX1C9uuSYVCFQvIkhBJcvmzrSXbEWMy2COQB65bC9N4D6tmkkgJkmlsU/6NBBhUDxLoYQMOeaQU8pvJgmBMz8O4CzOezSH8AXLKwHUJqIqphVHr+gQwfg8GFJb3n6tNWlUQIBQwgAdQ/5MVa2EUQCiHdYTrCtU1wxaBDQtCnw2GNAzZoy2ExRzESFICAoFI3FRDTSyJCWmJhodXGso1o1yW0cEwNcuwbMmWN1iRR/R4UgILBSCI4BqO6wXM22LhvM/DEzRzFzVAWT8/n6PERAmzZAz57AwoXagKeYiwpBQGClECwDMMzWe6g9gAvMfMLC8hQuBg8GjhwBNmywuiSKP6NCEBC4DDFRUIjoawBdAZQnogQALwIIBQBmngVgOYA+APYDSALwgFll8Uv695fsMgsWAO3bW10axV8xBpQBKgR+jGlCwMx357KdAYw26/p+T6lSQO/ewKJFwFtvAUGForlHKWyoRRAQaO1RmBk8GDh2DPjpJ/u6nTuBjAzryqT4F8nJQAlb/EkVAr9FhaAwc8cdQL16wJgxkk7wk0+AZs2AV1+1umSKv5CcDJQvL59VCPwWFYLCTHi4JBU/cAAYOlRSW4aGAlOn6oAzxTMkJwNFiwLFiqkQ+DEqBIWdm24Chg8Hvv1WBpmtWSOhAF5/3eqSKf5AcrK8cJQooULgx6gQ+APTpgEjRwL/+58kvR82DJg+HYiPz/1YRckJFYKAQIXAHyhXTlxEjRrJ8ksvZR55zCxhKdats6qESmElORkIC1Mh8HNUCPyRmjVl9PEvv8jyli0SqO79960tl1L4MCyCkiVVCPwYFQJ/pWdPCVl98SKwbJms++UXID3d2nIphQt1DQUEKgT+Ss+eQFoaEB0tbQehocDZs2IdKIq7pKSoEAQAKgT+SocO0uVv9mxg82ZpIwCAn3+2tlxK4UItgoBAhcBfKVIE6NbN7hZ6+GGgVSsVAiVvqBAEBCoE/kzPnjKvUwdo3FiW160z5w+9apUMatOw2P6FoxBcvSruRsXvUCHwZwwhuPVWyWPQsyeQmiqDzjzN/PnAV18B//zj+XMr1uEoBIBaBX6KCoE/07Ah8OWXwMSJstypk0QtHT8eSEjw7LViY2V+6JBnz6tYR1qaTCoEfo8Kgb8zdChQqZJ8DguTUBQJCSIK+/d75hrXrknUUwA4eNAz51Ssx8hFYAwoA1QI/BQVgkCjWzdxDV26BIwd65lz7tolLidALQJ/wshFoBaB36NCEIi0bi2RSpcvBw4fLvj5DLdQcLBaBP6ECkHAoEIQqIwcKQ3IH39c8HPFxgIREUBUlAqBP6FCEDCoEAQq1asD/foBn36aOS9tfoiNBa67DqhfX11D/oTxu1Ah8HtUCAKZRx8FEhOBJUvyfw5mEYJWrYDatSX0tdFeoBRu1CIIGFQIApkePWSg2bhxkuUMkMxmFy64f44jR2T/li1l4FpGBnD0qCnFVbyMCkHAoEIQyAQFAUuXSl/xXr2AJ58Ul1Hjxu4POjMaig0hALSdwF9wFILwcAlcmJeXBKXQoEIQ6DRqJNFJExKA994D7rpL3v66d5fl3NiyRRqdmzUT1xCgQuAvOAoBEVC5MnDihLVlUkzBVCEgol5EtIeI9hPRBCfbhxNRIhHF2qaHzSyP4oKOHYGNG4G4OGDePCAmBrjtNnEZ/fRTzseuXw80by6RTqtWlWB32mDsHzgKAQBERgLHjllXHsU0TBMCIgoGMANAbwBNANxNRE2c7LqAmVvapk/NKo+SC82aSa8fQCyC+fOlgh86VNoBnJGeLslvOnWS5eBgyY6mFoF/YAhBWJjMVQj8FjMtgnYA9jPzQWa+BuAbAP1NvJ7iSYoWld5EaWnAkCHOM5vt3CmNhx072tfVqaMWgb+gFkHAYKYQRAKId1hOsK3Lyp1EtI2IFhNRdRPLo+SVevWAWbPE/eOsvWDtWpkbFgEgQqAWgX/gTAguXdKeQ36I1Y3F/wNQi5mvA/ALgLnOdiKikUQUQ0QxiYmJXi1gwDNkiLQXPPccsG9f5m3r1kkDYq1a9nWNG0tKzG+/9WoxFRNwJgSAWgV+iJlCcAyA4xt+Ndu6f2HmM8xsDGv9FEAbZydi5o+ZOYqZoypUqGBKYRUXEAEzZ4qf+IEHMg8WW7tWrAEi+7qHHwauvx64917Nj1zYcRxZDKgQ+DFmCsFGAPWJqDYRFQEwBMAyxx2IqIrD4m0AdptYHiW/VK0KfPihVPxGboMTJ6QtwNEtBEjMoe++A8qVk4Q46kYovBgWQZEiMlch8FtCzDoxM6cR0WMAVgIIBjCbmXcS0SsAYph5GYAxRHQbgDQAZwEMN6s8SgG55x5xBb31lvQuMlJSOjYUG1SuDCxYINtmzgT+8x9zynT4MFC2LFCypDnnD3SM7GSGxadC4LcQF7Ics1FRURwTE2N1MQKTa9eAG2+UxmNA3v7Pn7e/MWalZ09g2zaxHCIinO+Tmgp88gkwbBhQvLj7ZUlLk4qpXj3gt9+AENPeaQKXJ54AvvgCOHfOvq5MGelSPH26deXyZVJT5QXF6IrtQxDRJmaOcrbN6sZipTBRpAjw66/AypVSeS9d6loEAOD554FTp4DPPnO9z8KFkhvhgw/yVpZ16yQ/8rp1wGuv5e1YxT0Mi8AR7UKaMzNmyJics2etLkmeUCFQ8kZEhLzpP/ywxCfKiRtuADp3BiZPBu67DxgzJnusms8/l/nHHzsfq+CKZctEhO64A3j5ZWDDhrzdh5I7ycn2wWQGKgQ5Ex2dOXVrIUGFQDGXKVNEPNaulQbnBx+0ty8cOSIWRuvWYk7//LP75/3f/4CuXYHZs6Uxe+TIvAmJkjtqEeQNZhlpDwC7C1e/FxUCxVy6dJE2goMHgTfeEHfSu+/Ktrm2YSPffANUrCiD19xhzx5g717plVS6NDB1qrRFzJtnxh0ELq6E4ORJaaNRMnPggOT3ACSPdyFChUDxHk8+Cdx+O/DMMzImYfZs4KabpGHtoYeAH36QxDbOuHpVYh/de6/EQQJECABg0CAZu/Dcc0BSklduJSBwJQQZGdL2o2Rm3TqZlymjQqAoLiESK2DkSGDRInENPfigbBs5UvIjTJrk/Nh584AdO4CvvgL++19JjVmzpv2806YBx48Db7/tnXuxmr17ge+/N/caKSnOhQBQ95Az1q2Trsz9+qkQKEqOlCwpbQXHj0vvoyFDZH2tWsDTTwNz5gB//JH5mIwMqeDbtJFtTZqIcDjSuTMwYADw+uviuvB33nhDckdcvGjeNVxZBIAKgTPWrQM6dACaNpXnU4iS+KgQKNZQsqT0Pgpy+Am+8IK85T/yCPDppzL/4Qdg+XJpF3jySRnJvHOndDnNyuuvy1vsiy967z6s4sAB8dNHR5t3DRUC97lwQSzWjh3lRQUoVA3GKgSK71C0qIwn2LkTGDFCupbeeitw991AtWrAwIE5H1+/PvDooyIiBem+l5gorihfHmxpRHjNLXFQQXAmBBUqSMpKVzkq/BXmnHul/fWX7OMoBIXIPaRCoPgWt94qb7m7d4vbY9o0GTX83HNSAeXGCy9IYp0HH5RRz87I7U89daqMdN68OV+3YDopKZJaFBD3mlmC5UwIgoKkJ9iCBYHVc2jcOBlVn5Xt24FbbpEIvcWKAe3aiZszPFyFQFEKRNeukku5SBHgqadklOaoUe4dW768tDNs2QJ06yZtCp9+Kj2Ujh0D/vxT/qy1awObNjk/x48/ynzBAk/cjec5ckQq//btpWvu/v3mXMeZEADA2LHSu2vJEnOu64v8+aeMhcna/jR6tKR2HTtWrIKSJSVTX6NGKgSK4lEcw1y7w+23y8jjPXtkdPOIEdI9tVo1eZs1ErB36QIsXpz52MOH5Q8cEiJC4IvuIcMt9MgjMjfLPeRsZDEA9O0rMZ7eecec6/oazPJbAjK3yWzYIC8akyYBb74p3ZsNmjRRIVAUy+nVS974Fy+WhDrbt8uf9e23pevlxo1Ay5bS7vDKK/YKf/lymU+YABw9ag+w50sYQtCjh1TIK1eacx1XFkFQkASk27DBPpLWnzl+HLh8WT6vXm1fP22aDGg0ukA70qSJWG6FJAy7CoHivzRuDNx5p1SWzZrJQLZx46RRulIlCW9x333Sy2joUIkc+eOPQN26sm9YmG+6hw4elAq6cmXxT0dH23MHeApm5+MIDIYPl4FTgwaZJ0S+gmENlC8vvxlAem0tXSouyxIlsh/TqpXMC0mkZBUCJXAJD5cBbq++Cnz9tYxa/vVXoE8f8fX26SPRUX0thtHBg5IbmkjcNElJwJo1nr1G1uxkWSleXASgRAmxvvr1E+vLOM6fiIuT+UMPSZvMoUPiDgoOlkCKzujQQb6fP//0XjkLgAqBEtgQAc8+K6GsFy6UN+u+fWXb8OHSnjB1qqVFzIYhBIA0iBctKuMtPIkRRrloUdf7tG0rPateeknmAwdKbyuDSZOksb+ws2eP9Ai67z5ZfvxxGeH+7LNAlSrOjylTRqzQQiIEYOZCNbVp04YVxRT++1/mqCjmq1dlOSODedAg5pAQ5pgYa8tmkJHBXKIE85gx9nX9+zPXrCnbPMV77zEDzNu2ubd/Whrz448zBwUxx8czJyYyFynCHBzMfPKk58plBT17MrdpI8+3UiV5Lu3bM6em5nzco48yFy+e+35eApIZ0mm9qhaBohg8/7w0IhvuECKJiFq5sqTq3LLF2vIBwJkz0gBpWASAuGWOHJGRrZ5izhwJD+7YEyYngoOlATkjQwYCzp4tcfnT04Evv/Rcuaxgzx6gYUP5PfTsKdbBl1/mnhWvc2dpZN62zTvlLAAqBIqSE2XKSLTTkyelYuzdW3odWYXRY6h2bfu6Pn1k7in30LZtInrDh+ftuLp1ge7dJSPdrFnSdbd9exEVX+yG6w5JSSKyjRrJ8nvvyfOpWzf3Yzt3lrnhHvLhrGUqBIqSGzfcIF1Jp0yR7qQtWkjXQcdcvt7CEAJHi6BqVQnI5ykhmDtXRnHffXfejx0xQirOQ4ck3Mfw4WKpuBq85+sYom8IQZkymZ99TlSvDtSoIWMNxo8HypWTtigfFEUVAkVxh1KlgIkTZZBQjx7SvbR8eRml/Nxz0r983z6xHGJjZUDbunUSt9+Tf3xnFgEgkVfXrROBKgjJyWIB9esn95dXbr9dKrzKlSWN6ODB0g333Xc938XVGxhdRxs2zN/xnTtLN9M33wQaNJAG5sce87meaLk4uRRFyUSVKpIHYP166T75yy8SEnrKFNfHFC8uYxmMqUYNeYuPjJT5tWsiIBUq2LuFOnL1KvDJJ9Kr6e+/5ZhixTLv8/TTwNatIlCHDkmU1mrVpCIKcvN9j1ne4k+dch7d1R3CwqRHTXCwhAgpUkSsgo8+AlasECujTx8JI+KqR1JamoQDqV7d/bKbRVycfB/16+fv+K5d5XmMGgVMny5C8OabMkjtq68kjasPQOyDZkpOREVFcUwhGaShBAgXL4ownDolnytXlkrs9GmJA7R/vwxA2r9f3uhzCtZWo4aMeK5USRqtk5PF5XPihLh/uneXPARt22Y/Nj1dKvCPPrKva9xY3kDr1hWrhlnOeeiQuLvS06XRs1kzKdt//iON5v/9r+eeT0aGjM/4+GO5l6tXZZzGgw/KGATDkipdGvjnH4n8evKkuGGaN5cyBwWJuPXoIX30nYW+yCvMIuaXL4u7b9s2cYtFRoq4Z2RI+U6dkueVH9LSgN9/F0EwRO2DD6RhvUMH4K23JLteXsOo5AMi2sTMUU63mSkERNQLwHsAggF8ysyvZ9keBuALAG0AnAEwmJkP53ROFQKlUJOeLhXL8eMyHTsmb82VK0uco+hoqRhPnZLBWWFhkujkhRekMnGHxERpmNy40Z7P2RVBQVLhGfTpI26t4OCC3KVrrl6VivGLL8TCMUSRSCrm4GAZx3HzzRIWZNcueT5JSTJKNz1dLImOHYGyZeX5lC8vU0aGnK9iRRHi0qVl36JF5c07IkL2P3tWfP+vvpq9n3+VKvLsjex3R4+KsD70kGefw5IlMuYiKcluKZYrJx0SOneW65cpI/fuISwRAiIKBrAXQA8ACQA2AribmXc57PMogOuYeRQRDQFwBzMPzum8KgSKkgeYRVhOn5bkKURSudSsKdZHaKgITmysNOoOHChv697gxAkJN96woVTAV67IemchGwCxttasEXfcunVSiSYny70ZsYDyQsWKYvm0bi1utapVpXvo+vUScoQZ+OYbeXM3g4sXZTT2t9+K+Jw6JcLjSLFiIgjh4WK5jRghCZrygVVC0AHAS8x8i215IgAw82sO+6y07fMXEYUAOAmgAudQKBUCRVGykZIi1k1wsFSo8fEy3iIpSaYrV0Q0kpPFUqheXbq2uhKda9dECDzhgsoLx49LIL9Tp8RyOXtWeqelpIg1dNttIlL5ICchMLOxOBJAvMNyAoDrXe3DzGlEdAFAOQCnTSyXoij+hmOFXaWK69AP7uJBl0yeqFpVAiV6mULRfZSIRhJRDBHFJCYmWl0cRVEUv8JMITgGoLrDcjXbOqf72FxDpSCNxplg5o+ZOYqZoypUqGBScRVFUQITM4VgI4D6RFSbiIoAGAJgWZZ9lgG43/b5LgC/5tQ+oCiKonge09oIbD7/xwCshHQfnc3MO4noFUgUvGUAPgMwj4j2AzgLEQtFURTFi5g6spiZlwNYnmXdJIfPyQAGmlkGRVEUJWcKRWOxoiiKYh4qBIqiKAGOCoGiKEqAU+iCzhFRIoAj+Ty8PHx/sJqW0TNoGT2DlrHg+Er5ajKz0/73hU4ICgIRxbgaYu0raBk9g5bRM2gZC46vlw9Q15CiKErAo0KgKIoS4ASaEHxsdQHcQMvoGbSMnkHLWHB8vXyB1UagKIqiZCfQLAJFURQlCyoEiqIoAU7ACAER9SKiPUS0n4gmWF0eACCi6kQUTUS7iGgnET1hW1+WiH4hon22eRmLyxlMRFuI6Afbcm0i2mB7lgts0WWtLF9pIlpMRHFEtJuIOvjgMxxn+453ENHXRBRu9XMkotlE9A8R7XBY5/S5kfC+razbiKi1hWWcavuutxHRt0RU2mHbRFsZ9xDRLVaV0WHbU0TERFTetmzJc8yNgBACW/7kGQB6A2gC4G4iamJtqQAAaQCeYuYmANoDGG0r1wQAq5m5PoDVtmUreQLAboflNwC8w8z1AJwD4OHM3nnmPQA/MXMjAC0gZfWZZ0hEkQDGAIhi5maQaLxDYP1znAOgV5Z1rp5bbwD1bdNIADMtLOMvAJox83WQvOgTAcD23xkCoKntmA9t/30ryggiqg6gJwDHRMRWPcccCQghANAOwH5mPsjM1wB8A6C/xWUCM59g5s22z5cgFVgkpGxzbbvNBXC7JQUEQETVAPQF8KltmQDcBGCxbRery1cKwA2QkOZg5mvMfB4+9AxthACIsCVgKgrgBCx+jsz8OyT8uyOunlt/AF+wsB5AaSIqYD7I/JWRmX9m5jTb4npI0iujjN8wcwozHwKwH/Lf93oZbbwD4D8AHHvkWPIccyNQhMBZ/uRIi8riFCKqBaAVgA0AKjHzCdumkwAqWVUuAO9CfswZtuVyAM47/BGtfpa1ASQC+NzmvvqUiIrBh54hMx8DMA3yZngCwAUAm+Bbz9HA1XPz1f/QgwBW2D77TBmJqD+AY8y8NcsmnymjI4EiBD4NERUHsATAWGa+6LjNlrHNkj6+RNQPwD/MvMmK67tJCIDWAGYycysAV5DFDWTlMwQAm5+9P0S0qgIoBieuBF/D6ueWG0T0HMS9Ot/qsjhCREUBPAtgUm77+gqBIgTu5E+2BCIKhYjAfGZealt9yjAXbfN/LCpeJwC3EdFhiDvtJog/vrTNxQFY/ywTACQw8wbb8mKIMPjKMwSAmwEcYuZEZk4FsBTybH3pORq4em4+9R8iouEA+gEY6pDe1lfKWBci+ltt/51qADYTUWX4ThkzEShC4E7+ZK9j87d/BmA3M7/tsMkxl/P9AL73dtkAgJknMnM1Zq4FeWa/MvNQANGQHNOWlg8AmPkkgHgiamhb1R3ALvjIM7RxFEB7Iipq+86NMvrMc3TA1XNbBmCYrddLewAXHFxIXoWIekHclbcxc5LDpmUAhhBRGBHVhjTI/u3t8jHzdmauyMy1bP+dBACtbb9Vn3mOmWDmgJgA9IH0MDgA4Dmry2MrU2eI6b0NQKxt6gPxw68GsA/AKgBlfaCsXQH8YPtcB/IH2w9gEYAwi8vWEkCM7Tl+B6CMrz1DAC8DiAOwA8A8AGFWP0cAX0PaLFIhldVDrp4bAIL0vDsAYDukB5RVZdwP8bMb/5lZDvs/ZyvjHgC9rSpjlu2HAZS38jnmNmmICUVRlAAnUFxDiqIoigtUCBRFUQIcFQJFUZQAR4VAURQlwFEhUBRFCXBUCBQlC0SUTkSxDpPHAtYRUS1nUSoVxUpCct9FUQKOq8zc0upCKIq3UItAUdyEiA4T0ZtEtJ2I/iaierb1tYjoV1t8+dVEVMO2vpItXv5W29TRdqpgIvqEJD/Bz0QUYdlNKQpUCBTFGRFZXEODHbZdYObmAKZDIrMCwAcA5rLEx58P4H3b+vcB/MbMLSDxj3ba1tcHMIOZmwI4D+BOU+9GUXJBRxYrShaI6DIzF3ey/jCAm5j5oC1Y4ElmLkdEpwFUYeZU2/oTzFyeiBIBVGPmFIdz1ALwC0viFxDReAChzDzZC7emKE5Ri0BR8ga7+JwXUhw+p0Pb6hSLUSFQlLwx2GH+l+3zOkh0VgAYCuAP2+fVAB4B/s37XMpbhVSUvKBvIoqSnQgiinVY/omZjS6kZYhoG+St/m7buschGdKegWRLe8C2/gkAHxPRQ5A3/0cgUSoVxafQNgJFcRNbG0EUM5+2uiyK4knUNaQoihLgqEWgKIoS4KhFoCiKEuCoECiKogQ4KgSKoigBjgqBoihKgKNCoCiKEuD8P2oPtUArhf/pAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, training_loss, color='r', label='train_loss')\n",
    "plt.plot(epochs, validation_loss, color='b', label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss Metric')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AS AMONG ALL THE MODELS (ANN INCLUDED), THE BEST ONE THAT WORKED WAS LOGISTIC REGRESSION, WE SHALL EXPORT THAT AND MAKE A SCRIPT TO IMPORT THE MODEL AND CLASSIFY AN AUDIO FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***EXPORTING***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "final_model = LogisticRegression(max_iter = 1000, C= 10, penalty= 'l2', solver= 'newton-cg')\n",
    "final_model.fit(mm_X_train, Y_train)\n",
    "\n",
    "model_file = open('logistic_classifier', 'ab')\n",
    "scaler_file = open('minmax_scaler', 'ab')\n",
    "      \n",
    "pickle.dump(final_model, model_file)\n",
    "pickle.dump(scaler1, scaler_file)\n",
    "model_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***FUNCTION TO READ AND CLASSIFY A FILE***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blues']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import librosa\n",
    "\n",
    "scaler_file = open('minmax_scaler', 'rb')     \n",
    "scaler = pickle.load(scaler_file)\n",
    "\n",
    "predictor_file = open('logistic_classifier', 'rb')\n",
    "predictor = pickle.load(predictor_file)\n",
    "\n",
    "def music_classification(filepath):\n",
    "    audio, sample_rate = librosa.load(filepath)\n",
    "    features_list = []\n",
    "\n",
    "    features = librosa.feature.mfcc(y=audio, sr = sample_rate, n_mfcc= 30)\n",
    "    averaged_features = np.mean(features, axis=1)\n",
    "    variance_features = np.var(features, axis=1)\n",
    "    features_list.extend(averaged_features)\n",
    "    features_list.extend(variance_features)\n",
    "\n",
    "    tempo_beat = librosa.beat.beat_track(y=audio, sr = sample_rate)\n",
    "    tempo = tempo_beat[0]\n",
    "    beat_mean = np.mean(tempo_beat[1])\n",
    "    beat_var = np.var(tempo_beat[1])\n",
    "    features_list.append(tempo)\n",
    "    features_list.append(beat_mean)\n",
    "    features_list.append(beat_var)\n",
    "\n",
    "    onset = librosa.onset.onset_strength(y=audio, sr = sample_rate)\n",
    "    averaged_onset = np.mean(onset)\n",
    "    variance_onset = np.var(onset)\n",
    "    features_list.append(averaged_onset)\n",
    "    features_list.append(variance_onset)\n",
    "\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr = sample_rate)\n",
    "    averaged_mel = np.mean(mel_spectrogram, axis = 1)\n",
    "    variance_mel = np.var(mel_spectrogram, axis = 1)\n",
    "    features_list.extend(averaged_mel)\n",
    "    features_list.extend(variance_mel)\n",
    "\n",
    "    chroma_cens = librosa.feature.chroma_cens(y=audio, sr = sample_rate)\n",
    "    averaged_cens = np.mean(chroma_cens, axis = 1)\n",
    "    variance_cens = np.var(chroma_cens, axis = 1)\n",
    "    features_list.extend(averaged_cens)\n",
    "    features_list.extend(variance_cens)\n",
    "\n",
    "    chroma_cqt = librosa.feature.chroma_cqt(y=audio, sr = sample_rate)\n",
    "    averaged_cqt = np.mean(chroma_cqt, axis = 1)\n",
    "    variance_cqt = np.var(chroma_cqt, axis = 1)\n",
    "    features_list.extend(averaged_cqt)\n",
    "    features_list.extend(variance_cqt)\n",
    "\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=audio, sr = sample_rate)\n",
    "    averaged_stft = np.mean(chroma_stft, axis = 1)\n",
    "    variance_stft = np.var(chroma_stft, axis = 1)\n",
    "    features_list.extend(averaged_stft)\n",
    "    features_list.extend(variance_stft)\n",
    "\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr = sample_rate)\n",
    "    averaged_rolloff = np.mean(spectral_rolloff, axis = 1)\n",
    "    variance_rolloff = np.var(spectral_rolloff, axis = 1)\n",
    "    features_list.extend(averaged_rolloff)\n",
    "    features_list.extend(variance_rolloff)\n",
    "\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr = sample_rate)\n",
    "    averaged_bandwidth = np.mean(spectral_bandwidth, axis = 1)\n",
    "    variance_bandwidth = np.var(spectral_bandwidth, axis = 1)\n",
    "    features_list.extend(averaged_bandwidth)\n",
    "    features_list.extend(variance_bandwidth)\n",
    "\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=audio, sr = sample_rate)\n",
    "    averaged_contrast = np.mean(spectral_contrast, axis = 1)\n",
    "    variance_contrast = np.var(spectral_contrast, axis = 1)\n",
    "    features_list.extend(averaged_contrast)\n",
    "    features_list.extend(variance_contrast)\n",
    "\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=audio, sr = sample_rate)\n",
    "    averaged_centroid = np.mean(spectral_centroid, axis = 1)\n",
    "    variance_centroid = np.var(spectral_centroid, axis = 1)\n",
    "    features_list.extend(averaged_centroid)\n",
    "    features_list.extend(variance_centroid)\n",
    "\n",
    "    spectral_flatness = librosa.feature.spectral_flatness(y=audio)\n",
    "    averaged_flatness = np.mean(spectral_flatness, axis = 1)\n",
    "    variance_flatness = np.var(spectral_flatness, axis = 1)\n",
    "    features_list.extend(averaged_flatness)\n",
    "    features_list.extend(variance_flatness)\n",
    "\n",
    "    features_list = scaler1.transform([features_list])\n",
    "\n",
    "    print(predictor.predict(features_list))\n",
    "music_classification('Data/genres_original/blues/blues.00001.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***CONFUSION MATRIX (CLASSIFICATION METRIC)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index-0: blues\n",
      "Index-1: classical\n",
      "Index-2: country\n",
      "Index-3: disco\n",
      "Index-4: hiphop\n",
      "Index-5: jazz\n",
      "Index-6: metal\n",
      "Index-7: pop\n",
      "Index-8: reggae\n",
      "Index-9: rock\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = predictor.predict(mm_X_test)\n",
    "\n",
    "labels = sorted(np.unique(predictions))\n",
    "predictions_index = [labels.index(i) for i in predictions]\n",
    "actual_index = [labels.index(i) for i in Y_test]\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    print('Index-{}: {}'.format(i, labels[i]))\n",
    "plt.figure(figsize = (10, 7))\n",
    "sns.heatmap(data = confusion_matrix(predictions_index, actual_index), cmap = 'Greys_r', annot = True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb4569285eef3a3450cb62085a5b1e0da4bce0af555edc33dcf29baf3acc1368"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
